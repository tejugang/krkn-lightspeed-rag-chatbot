{
  "items": [
    {
    "user_input": "What is the primary objective of the 'Pod Scenarios' feature within Krkn-hub on a Kubernetes/OpenShift cluster?",
    "generated_answer": "The primary objective of the 'Pod Scenarios' feature within Krkn-hub on a Kubernetes/OpenShift cluster is to disrupt pods matching specified labels or patterns, simulating chaos in the system. This allows for testing and validation of the cluster's resilience and recovery capabilities. The disruption can be configured with parameters such as disruption count, kill timeout, and expected recovery time.",
    "retrieved_context": ["Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:"],
    "reference_answer": "The primary objective of the 'Pod Scenarios' feature in Krkn-hub is to disrupt pods that match a specified label within a designated namespace on either a Kubernetes or OpenShift cluster, simulating chaos conditions."
  },
  {
    "user_input": "How can Cerberus be integrated with Krkn-hub's pod scenarios to monitor the cluster and determine the success or failure of a chaos injection?",
    "generated_answer": "To integrate Cerberus with Krkn-hub's pod scenarios, start Cerberus before injecting chaos and set the CERBERUS_ENABLED environment variable to autoconnect. You can then use $ podman inspect <container-name or container-id> --format \"{{.State.ExitCode}}\" to output an exit code that can be considered as pass/fail for the scenario.",
    "retrieved_context": ["Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:"],
    "reference_answer": "To integrate Cerberus, it must be started before injecting chaos. For the chaos injection container to auto-connect with Cerberus and enable monitoring for pass/fail evaluation, the `CERBERUS_ENABLED` environment variable must be set."
  },
  {
    "user_input": "What is the standard Podman command structure for initiating a pod disruption scenario with Krkn-hub, including how to provide the kube config and enable host environment variables?",
    "generated_answer": "To initiate a pod disruption scenario with Krkn-hub using Podman, run the following command:\n```\n$ podman run --name=<container_name> --net=host --env-host=true -v <path-to-kube-config>:/home/krkn/.kube/config:Z -d containers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n```\nThis command includes the kube config and enables host environment variables. The namespace, pod label, and disruption count can be customized with additional parameters.",
    "retrieved_context": ["Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy  \nNote  \u2013env-host:  This  option  is  not  available  with  the  remote  Podman  client,  including  Mac  and  \nWindows\n \n(excluding\n \nWSL2)\n \nmachines.\n \nWithout\n \nthe\n \n\u2013env-host\n \noption\n \nyou\u2019ll\n \nhave\n \nto\n \nset\n \neach\n \nenviornment\n \nvariable\n \non\n \nthe\n \npodman\n \ncommand\n \nline\n \nlike\n \n-e\n \n<VARIABLE>=<value>\n \n$  docker  run  $(./get_docker_params.sh)  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n OR   $  docker  run  -e  <VARIABLE>=<value>  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n  $  docker  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  docker  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario"],
    "reference_answer": "The standard Podman command is `podman run --name=<container_name> --net=host --env-host=true -v <path-to-kube-config>:/home/krkn/.kube/config:Z -d containers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios`. This command runs the scenario container, mounts the kube config, and uses `--env-host=true` to allow the container to access host environment variables."
  },
  {
    "user_input": "After a Krkn-hub pod scenario has been initiated, what commands can be used with both Podman and Docker to monitor its ongoing logs and to retrieve its final exit code for pass/fail determination?",
    "generated_answer": "You can use the following commands to monitor logs and retrieve exit codes:\n\n* Docker: `docker logs -f <container_name or container_id>` for logs, and `docker inspect <container-name or container_id> --format \"{{.State.ExitCode}}\"` for exit code.\n* Podman: `podman logs -f <container_name or container_id>` for logs, and `podman inspect <container-name or container_id> --format \"{{.State.ExitCode}}\"` for exit code.",
    "retrieved_context": ["Outputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy  \nNote  \u2013env-host:  This  option  is  not  available  with  the  remote  Podman  client,  including  Mac  and  \nWindows\n \n(excluding\n \nWSL2)\n \nmachines.\n \nWithout\n \nthe\n \n\u2013env-host\n \noption\n \nyou\u2019ll\n \nhave\n \nto\n \nset\n \neach\n \nenviornment\n \nvariable\n \non\n \nthe\n \npodman\n \ncommand\n \nline\n \nlike\n \n-e\n \n<VARIABLE>=<value>\n \n$  docker  run  $(./get_docker_params.sh)  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n OR   $  docker  run  -e  <VARIABLE>=<value>  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n  $  docker  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  docker  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\n$  docker  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  docker  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy"],
    "reference_answer": "To monitor ongoing logs, use `podman logs -f <container_name or container_id>` or `docker logs -f <container_name or container_id>`. To determine the final outcome (pass/fail), the exit code can be retrieved using `podman inspect <container-name or container_id> --format \"{{.State.ExitCode}}\"` or `docker inspect <container-name or container_id> --format \"{{.State.ExitCode}}\"`."
  },
  {
    "user_input": "What is a significant limitation of the `--env-host` option when running Krkn-hub scenarios with Podman on certain client types, and how should environment variables be managed in such cases?",
    "generated_answer": "A significant limitation of the `--env-host` option when running Krkn-hub scenarios with Podman on certain client types (Mac and Windows, excluding WSL2) is its unavailability. Without this option, environment variables must be set on the podman command line or exported as a variable prior to running the container.",
    "retrieved_context": ["Outputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy  \nNote  \u2013env-host:  This  option  is  not  available  with  the  remote  Podman  client,  including  Mac  and  \nWindows\n \n(excluding\n \nWSL2)\n \nmachines.\n \nWithout\n \nthe\n \n\u2013env-host\n \noption\n \nyou\u2019ll\n \nhave\n \nto\n \nset\n \neach\n \nenviornment\n \nvariable\n \non\n \nthe\n \npodman\n \ncommand\n \nline\n \nlike\n \n-e\n \n<VARIABLE>=<value>\n \n$  docker  run  $(./get_docker_params.sh)  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n OR   $  docker  run  -e  <VARIABLE>=<value>  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n  $  docker  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  docker  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #\n\nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:  \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-custom-metrics-profile>:/home/krkn/kraken/config/metrics-aggregated.yaml\n \n-v\n \n<path-to-custom-alerts-profile>:/home/krkn/kraken/config/alerts\n \n-v\n \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:container-scenarios\n \nCopy\n\nNone \n None \nTip  Because  the  container  runs  with  a  non-root  user,  ensure  the  kube  config  is  globally  readable  \nbefore\n \nmounting\n \nit\n \nin\n \nthe\n \ncontainer.\n \nYou\n \ncan\n \nachieve\n \nthis\n \nwith\n \nthe\n \nfollowing\n \ncommands:\n \nkubectl\n \nconfig\n \nview\n \n--flatten\n \n>\n \n~/kubeconfig\n \n&&\n \nchmod\n \n444\n \n~/kubeconfig\n \n&&\n \ndocker\n \nrun\n \n$(./get_docker_params.sh)\n \n--name=<container_name>\n \n--net=host\n \n-v\n \n~kubeconfig:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:<scenario>\n \nSupported  parameters  The  following  environment  variables  can  be  set  on  the  host  running  the  container  to  tweak  the  \nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help"],
    "reference_answer": "The `--env-host` option is not available with remote Podman clients, including those on Mac and Windows (excluding WSL2). In these situations, environment variables must be set individually on the Podman command line using the `-e <VARIABLE>=<value>` syntax for each variable."
  },
  {
    "user_input": "Why is it crucial to adjust the permissions of the kube config file before mounting it into the Krkn-hub container, and what specific commands are recommended to achieve this?",
    "generated_answer": "It is crucial to adjust the permissions of the kube config file before mounting it into the Krkn-hub container because the container runs with a non-root user. To achieve this, you can use the following commands:\n\n1. `kubectl config view --flatten > ~/kubeconfig`\n2. `chmod 444 ~/kubeconfig`\n\nThis ensures the kube config is globally readable by the container.",
    "retrieved_context": ["None \n None \nTip  Because  the  container  runs  with  a  non-root  user,  ensure  the  kube  config  is  globally  readable  \nbefore\n \nmounting\n \nit\n \nin\n \nthe\n \ncontainer.\n \nYou\n \ncan\n \nachieve\n \nthis\n \nwith\n \nthe\n \nfollowing\n \ncommands:\n \nkubectl\n \nconfig\n \nview\n \n--flatten\n \n>\n \n~/kubeconfig\n \n&&\n \nchmod\n \n444\n \n~/kubeconfig\n \n&&\n \ndocker\n \nrun\n \n$(./get_docker_params.sh)\n \n--name=<container_name>\n \n--net=host\n \n-v\n \n~kubeconfig:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:<scenario>\n \nSupported  parameters  The  following  environment  variables  can  be  set  on  the  host  running  the  container  to  tweak  the  \nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:  \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-custom-metrics-profile>:/home/krkn/kraken/config/metrics-aggregated.yaml\n \n-v\n \n<path-to-custom-alerts-profile>:/home/krkn/kraken/config/alerts\n \n-v\n \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:container-scenarios\n \nCopy\n\nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy  \nNote  \u2013env-host:  This  option  is  not  available  with  the  remote  Podman  client,  including  Mac  and  \nWindows\n \n(excluding\n \nWSL2)\n \nmachines.\n \nWithout\n \nthe\n \n\u2013env-host\n \noption\n \nyou\u2019ll\n \nhave\n \nto\n \nset\n \neach\n \nenviornment\n \nvariable\n \non\n \nthe\n \npodman\n \ncommand\n \nline\n \nlike\n \n-e\n \n<VARIABLE>=<value>\n \n$  docker  run  $(./get_docker_params.sh)  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n OR   $  docker  run  -e  <VARIABLE>=<value>  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n  $  docker  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  docker  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #"],
    "reference_answer": "It is crucial because the Krkn-hub container runs with a non-root user, requiring the kube config to be globally readable. This can be achieved by first flattening the config and saving it (`kubectl config view --flatten > ~/kubeconfig`), and then changing its permissions to `444` (`chmod 444 ~/kubeconfig`) before mounting."
  },
  {
    "user_input": "How can environment variables be passed to a Krkn-hub scenario container to customize its behavior, detailing both the host-based and command-line methods?",
    "generated_answer": "To pass environment variables to a Krkn-hub scenario container, you can use either the host-based method with the `--env-host` option or set each variable on the command line with `-e <VARIABLE>=<value>`. For example: `$ docker run $(./get_docker_params.sh) --name=<container_name> --net=host -v <path-to-kube-config>:/home/krkn/.kube/config:Z -d containers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios -e VARIABLE=value`.",
    "retrieved_context": ["Outputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy  \nNote  \u2013env-host:  This  option  is  not  available  with  the  remote  Podman  client,  including  Mac  and  \nWindows\n \n(excluding\n \nWSL2)\n \nmachines.\n \nWithout\n \nthe\n \n\u2013env-host\n \noption\n \nyou\u2019ll\n \nhave\n \nto\n \nset\n \neach\n \nenviornment\n \nvariable\n \non\n \nthe\n \npodman\n \ncommand\n \nline\n \nlike\n \n-e\n \n<VARIABLE>=<value>\n \n$  docker  run  $(./get_docker_params.sh)  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n OR   $  docker  run  -e  <VARIABLE>=<value>  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n  $  docker  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  docker  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #\n\nNone \n None \nTip  Because  the  container  runs  with  a  non-root  user,  ensure  the  kube  config  is  globally  readable  \nbefore\n \nmounting\n \nit\n \nin\n \nthe\n \ncontainer.\n \nYou\n \ncan\n \nachieve\n \nthis\n \nwith\n \nthe\n \nfollowing\n \ncommands:\n \nkubectl\n \nconfig\n \nview\n \n--flatten\n \n>\n \n~/kubeconfig\n \n&&\n \nchmod\n \n444\n \n~/kubeconfig\n \n&&\n \ndocker\n \nrun\n \n$(./get_docker_params.sh)\n \n--name=<container_name>\n \n--net=host\n \n-v\n \n~kubeconfig:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:<scenario>\n \nSupported  parameters  The  following  environment  variables  can  be  set  on  the  host  running  the  container  to  tweak  the  \nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy"],
    "reference_answer": "Environment variables can be passed by setting them on the host running the container using `export <parameter_name>=<value>` if the `--env-host` option is used. Alternatively, they can always be passed directly on the command line when running the container using the `-e <VARIABLE>=<value>` flag."
  },
  {
    "user_input": "What is the function of the `NAMESPACE` parameter in Krkn-hub pod scenarios, and what is its default value, including its support for advanced matching?",
    "generated_answer": "The `NAMESPACE` parameter in Krkn-hub pod scenarios specifies the targeted namespace in the cluster, supporting regex patterns. Its default value is `openshift-*`. This parameter enables advanced matching by allowing users to specify a namespace pattern instead of a fixed name.",
    "retrieved_context": ["Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario"],
    "reference_answer": "The `NAMESPACE` parameter specifies the targeted namespace(s) within the cluster where the pod disruption will occur. It supports regular expressions for flexible matching, and its default value is `openshift-.*`, which targets all OpenShift system namespaces."
  },
  {
    "user_input": "Explain the interplay between the `POD_LABEL` and `NAME_PATTERN` parameters in determining which pods are targeted for disruption, and what their default behaviors are.",
    "generated_answer": "Here's a concise explanation of the interplay between `POD_LABEL` and `NAME_PATTERN` parameters:\n\nWhen `POD_LABEL` is specified, it targets pods with that label. If `POD_LABEL` is not specified, `NAME_PATTERN` is used to match pods in the targeted namespace. Both parameters are regex patterns.\n\nTheir default behaviors are: `POD_LABEL` is empty by default (\"\"), and `NAME_PATTERN` defaults to \".*\".",
    "retrieved_context": ["Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy"],
    "reference_answer": "The `POD_LABEL` parameter specifies the label of the pod(s) to target, with a default of an empty string. If `POD_LABEL` is not specified, the `NAME_PATTERN` parameter is used instead to match pods within the `NAMESPACE` using a regex pattern. The `NAME_PATTERN` defaults to `.*`, meaning it will match all pods in the targeted namespace if no specific label is provided."
  },
  {
    "user_input": "What do the `DISRUPTION_COUNT`, `KILL_TIMEOUT`, and `EXPECTED_RECOVERY_TIME` parameters control in a Krkn-hub pod scenario, and what are their default values?",
    "generated_answer": "The `DISRUPTION_COUNT` parameter controls the number of pods to disrupt, with a default value of 1. The `KILL_TIMEOUT` parameter sets the timeout in seconds for the target pod(s) to be removed, with a default value of 180 seconds. The `EXPECTED_RECOVERY_TIME` parameter fails if the disrupted pod does not recover within the specified timeout set by `--kill-timeout`.",
    "retrieved_context": ["Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy"],
    "reference_answer": "The `DISRUPTION_COUNT` parameter specifies the number of pods to disrupt, defaulting to `1`. The `KILL_TIMEOUT` parameter sets the maximum time (in seconds) to wait for target pods to be removed, defaulting to `180`. The `EXPECTED_RECOVERY_TIME` parameter defines the timeout (in seconds) for disrupted pods to recover, defaulting to `120`, and the scenario fails if recovery doesn't occur within this period."
  },
  {
    "user_input": "Beyond specific namespace targeting, how can the `NAMESPACE` environment variable be configured to randomly disrupt pods in OpenShift system namespaces, and what additional mode can be enabled for continuous reliability testing?",
    "generated_answer": "To disrupt pods in OpenShift system namespaces randomly, set the `NAMESPACE` environment variable to \"openshift-.*\". To enable continuous reliability testing, you can use the `DAEMON_MODE` option with a value for the interval at which to disrupt pods. This mode allows for background disruption of pods every x seconds.",
    "retrieved_context": ["Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:\n\nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy"],
    "reference_answer": "The `NAMESPACE` environment variable can be set to `openshift-.*` to randomly select and disrupt pods within OpenShift system namespaces. For continuous reliability testing, `DAEMON_MODE` can be enabled to disrupt pods every 'x' seconds in the background."
  },
  {
    "user_input": "When `CAPTURE_METRICS` or `ENABLE_ALERTS` are active, how should custom metrics and alerts profiles be provided to the Krkn-hub container, including the specific internal paths for mounting?",
    "generated_answer": "When `CAPTURE_METRICS` or `ENABLE_ALERTS` are active, custom metrics and alerts profiles should be provided to the Krkn-hub container by mounting them from the host under `/home/krkn/kraken/config/metrics-aggregated.yaml` and `/home/krkn/kraken/config/alerts`. For example: `-v <path-to-custom-metrics-profile>:/home/krkn/kraken/config/metrics-aggregated.yaml -v <path-to-custom-alerts-profile>:/home/krkn/kraken/config/alerts`.",
    "retrieved_context": ["the\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:  \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-custom-metrics-profile>:/home/krkn/kraken/config/metrics-aggregated.yaml\n \n-v\n \n<path-to-custom-alerts-profile>:/home/krkn/kraken/config/alerts\n \n-v\n \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:container-scenarios\n \nCopy\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:\n\nNone \n None \nTip  Because  the  container  runs  with  a  non-root  user,  ensure  the  kube  config  is  globally  readable  \nbefore\n \nmounting\n \nit\n \nin\n \nthe\n \ncontainer.\n \nYou\n \ncan\n \nachieve\n \nthis\n \nwith\n \nthe\n \nfollowing\n \ncommands:\n \nkubectl\n \nconfig\n \nview\n \n--flatten\n \n>\n \n~/kubeconfig\n \n&&\n \nchmod\n \n444\n \n~/kubeconfig\n \n&&\n \ndocker\n \nrun\n \n$(./get_docker_params.sh)\n \n--name=<container_name>\n \n--net=host\n \n-v\n \n~kubeconfig:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:<scenario>\n \nSupported  parameters  The  following  environment  variables  can  be  set  on  the  host  running  the  container  to  tweak  the  \nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy"],
    "reference_answer": "When `CAPTURE_METRICS` or `ENABLE_ALERTS` are active, custom profiles must be mounted from the host into the container using volume mounts. The custom metrics profile should be mounted to `/home/krkn/kraken/config/metrics-aggregated.yaml`, and the custom alerts profile to `/home/krkn/kraken/config/alerts`."
  },
  {
    "user_input": "When executing a `pod-scenarios` run with `krknctl`, what are the different mechanisms available for precisely identifying the target pods for disruption, and how do they interact?",
    "generated_answer": "When executing a `pod-scenarios` run with `krknctl`, you can precisely identify the target pods for disruption using one of four mechanisms:\n1. The `--namespace` parameter, which targets a specific namespace (supports regex).\n2. The `--pod-label` parameter, which selects pods based on a specified label.\n3. The `--name-pattern` parameter, which matches pods in a namespace using a regex pattern.\n4. The `DISRUPTION_COUNT`, `KILL_TIMEOUT`, and `EXPECTED_RECOVERY_TIME` parameters, which can be used to disrupt multiple pods or set timeout and recovery time thresholds.\n\nThese mechanisms interact by allowing you to combine them to target specific pods for disruption.",
    "retrieved_context": ["Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:"],
    "reference_answer": "To precisely identify target pods for disruption, users can leverage three parameters: `--namespace`, `--pod-label`, and `--name-pattern`. The `--namespace` parameter allows targeting pods within a specific namespace, supporting regular expressions, with a default of `openshift-*`. The `--pod-label` parameter targets pods based on a specific label, such as \"app=test\". If `--pod-label` is not specified, the `--name-pattern` parameter, which defaults to `.*`, is used as a regex pattern to match pods within the specified `--namespace`."
  },
  {
    "user_input": "Describe the two critical timeout parameters in `krknctl run pod-scenarios` and explain their distinct roles in determining the scenario's outcome.",
    "generated_answer": "The two critical timeout parameters in `krknctl run pod-scenarios` are:\n\n* `KILL_TIMEOUT`: the timeout to wait for the target pod(s) to be removed in seconds (default 180)\n* `EXPECTED_RECOVERY_TIME`: the timeout to wait for a disrupted pod to recover, failing if it does not recover within this time (default 120)\n\nThese parameters determine the scenario's outcome by specifying how long to wait for pods to be removed or recovered.",
    "retrieved_context": ["Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy"],
    "reference_answer": "The two critical timeout parameters are `--kill-timeout` and `--expected-recovery-time`. The `--kill-timeout` parameter, defaulting to 180 seconds, specifies the maximum time to wait for the target pod(s) to be removed from the cluster. In contrast, the `--expected-recovery-time` parameter, defaulting to 120 seconds, dictates the maximum time allowed for a disrupted pod to recover. If a pod fails to recover within this `expected-recovery-time`, the entire scenario will be marked as a failure."
  },
  {
    "user_input": "If a user wants to disrupt more than one pod in a `pod-scenarios` run, which parameter needs to be adjusted, and what is the default behavior if this parameter is not explicitly set?",
    "generated_answer": "To disrupt more than one pod in a `pod-scenarios` run, you need to adjust the `--disruption-count` parameter. If this parameter is not explicitly set, the default behavior will be to disrupt only one pod.",
    "retrieved_context": ["Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nWhy  pod  scenarios  are  important:   \n \nUse  Cases  and  Importance  of  Pod-Level  Chaos  Scenarios  \n1.  Single  Pod  Deletion  \u25cf  Use  Case:  Simulates  unplanned  deletion  of  a  single  pod  \u25cf  Why  It's  Important:  Validates  whether  the  ReplicaSet  or  Deployment  automatically  \ncreates\n \na\n \nreplacement.\n \u25cf  Customer  Impact:  Ensures  continuous  service  even  if  a  pod  unexpectedly  crashes.  \u25cf  Recovery  Timing:  Typically  <10  seconds  for  stateless  apps  (seen  in  Krkn  telemetry  \noutput).\n \u25cf  HA  Indicator:  Pod  is  automatically  rescheduled  and  becomes  Ready  without  manual  \nintervention.\n  Kubectl  delete  pod  <pod-name> delete  pod  <pod-name>  Kubectl  get  pods  #  watch  for  new  pods \n2.  Multiple  Pods  Deleted  Simultaneously  \u25cf  Use  Case:  Simulates  a  larger  failure  event,  such  as  a  node  crash  or  AZ  outage.  \u25cf  Why  It's  Important:  Tests  whether  the  system  has  enough  resources  and  policies  to  \nrecover"],
    "reference_answer": "To disrupt more than one pod, the user needs to adjust the `--disruption-count` parameter. By default, if this parameter is not explicitly set, `krknctl run pod-scenarios` will only disrupt a single pod, as its default value is 1."
  },
  {
    "user_input": "What is the default scope for targeting pods in a `krknctl run pod-scenarios` execution if no specific namespace, label, or name pattern is provided by the user?",
    "generated_answer": "The default scope for targeting pods in a `krknctl run pod-scenarios` execution is the `openshift-*` namespace. If no specific namespace, label, or name pattern is provided by the user, krknctl will target pods in this namespace. The user can override this default using options such as `--namespace`.",
    "retrieved_context": ["Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario"],
    "reference_answer": "If no specific targeting parameters are provided, the `krknctl run pod-scenarios` execution will default to targeting pods within any namespace matching the `openshift-*` regex pattern, as specified by the `--namespace` parameter's default. Furthermore, within these namespaces, it will match any pod name due to the `--name-pattern` defaulting to `.*` when `--pod-label` is not specified."
  },
  {
    "user_input": "How can a user obtain a comprehensive list of all configurable options and their descriptions for the `krknctl run pod-scenarios` command?",
    "generated_answer": "To obtain a comprehensive list of all configurable options and their descriptions for the `krknctl run pod-scenarios` command, use the following command: `krknctl run pod-scenarios --help`. This will display a list of available scenario options. Alternatively, you can refer to the section \"Parameter Description\" in the provided context, which lists the default values and types for each parameter.",
    "retrieved_context": ["Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*"],
    "reference_answer": "A user can obtain a comprehensive list of all available scenario options and their descriptions for the `krknctl run pod-scenarios` command by executing `krknctl run pod-scenarios --help`."
  },
  {
    "user_input": "Differentiate between the 'Single Pod Deletion' and 'Multiple Pods Deleted Simultaneously' chaos scenarios regarding their simulated failure types and the primary customer impact each aims to validate or expose.",
    "generated_answer": "Here is the differentiation between 'Single Pod Deletion' and 'Multiple Pods Deleted Simultaneously' chaos scenarios:\n\nThe 'Single Pod Deletion' scenario simulates unplanned deletion of a single pod, validating whether the ReplicaSet or Deployment automatically creates a replacement. It ensures continuous service even if a pod unexpectedly crashes.\n\nIn contrast, the 'Multiple Pods Deleted Simultaneously' scenario simulates a larger failure event, such as a node crash or AZ outage, testing whether the system has enough resources and policies to recover from a more extensive disruption.",
    "retrieved_context": ["Why  pod  scenarios  are  important:   \n \nUse  Cases  and  Importance  of  Pod-Level  Chaos  Scenarios  \n1.  Single  Pod  Deletion  \u25cf  Use  Case:  Simulates  unplanned  deletion  of  a  single  pod  \u25cf  Why  It's  Important:  Validates  whether  the  ReplicaSet  or  Deployment  automatically  \ncreates\n \na\n \nreplacement.\n \u25cf  Customer  Impact:  Ensures  continuous  service  even  if  a  pod  unexpectedly  crashes.  \u25cf  Recovery  Timing:  Typically  <10  seconds  for  stateless  apps  (seen  in  Krkn  telemetry  \noutput).\n \u25cf  HA  Indicator:  Pod  is  automatically  rescheduled  and  becomes  Ready  without  manual  \nintervention.\n  Kubectl  delete  pod  <pod-name> delete  pod  <pod-name>  Kubectl  get  pods  #  watch  for  new  pods \n2.  Multiple  Pods  Deleted  Simultaneously  \u25cf  Use  Case:  Simulates  a  larger  failure  event,  such  as  a  node  crash  or  AZ  outage.  \u25cf  Why  It's  Important:  Tests  whether  the  system  has  enough  resources  and  policies  to  \nrecover\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:\n\nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario \nKill  a  pod.  :heavy_check_mark:  \nEtcd Kills  a  single/multiple  etcd  replicas.  \n:heavy_check_mark:"],
    "reference_answer": "The 'Single Pod Deletion' scenario simulates an unplanned, isolated failure of a single pod, primarily validating whether the ReplicaSet or Deployment automatically creates a replacement to ensure continuous service with minimal customer impact. In contrast, 'Multiple Pods Deleted Simultaneously' simulates a larger, more widespread failure event, such as a node crash or an Availability Zone outage. This scenario tests the system's ability to recover gracefully with sufficient resources and policies, as a failure of all pods belonging to a service in this scenario directly impacts user experience if not properly mitigated by distributed replicas."
  },
  {
    "user_input": "Explain the significance of 'Pod Eviction' as a chaos scenario, detailing its typical triggers and the specific configurations that are crucial for ensuring zero customer impact during such an event.",
    "generated_answer": "Here is a concise answer in three sentences:\n\n\"Pod Eviction\" is a chaos scenario where Kubernetes itself triggers the eviction of pods due to node upgrades or scaling down. The significance of this scenario is to ensure that the application can recover gracefully without user impact, with zero customer impact if readiness/liveness probes and PDBs are correctly configured. This scenario is crucial for testing rolling disruptions that do not take down the whole application.",
    "retrieved_context": ["Why  pod  scenarios  are  important:   \n \nUse  Cases  and  Importance  of  Pod-Level  Chaos  Scenarios  \n1.  Single  Pod  Deletion  \u25cf  Use  Case:  Simulates  unplanned  deletion  of  a  single  pod  \u25cf  Why  It's  Important:  Validates  whether  the  ReplicaSet  or  Deployment  automatically  \ncreates\n \na\n \nreplacement.\n \u25cf  Customer  Impact:  Ensures  continuous  service  even  if  a  pod  unexpectedly  crashes.  \u25cf  Recovery  Timing:  Typically  <10  seconds  for  stateless  apps  (seen  in  Krkn  telemetry  \noutput).\n \u25cf  HA  Indicator:  Pod  is  automatically  rescheduled  and  becomes  Ready  without  manual  \nintervention.\n  Kubectl  delete  pod  <pod-name> delete  pod  <pod-name>  Kubectl  get  pods  #  watch  for  new  pods \n2.  Multiple  Pods  Deleted  Simultaneously  \u25cf  Use  Case:  Simulates  a  larger  failure  event,  such  as  a  node  crash  or  AZ  outage.  \u25cf  Why  It's  Important:  Tests  whether  the  system  has  enough  resources  and  policies  to  \nrecover\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nrecover\n \ngracefully.\n \u25cf  Customer  Impact:  If  all  pods  of  a  service  fail,  user  experience  is  directly  impacted.  \u25cf  HA  Indicator:  Application  can  continue  functioning  from  other  replicas  across  \nzones/nodes.\n \n \n3.  Pod  Eviction  (Soft  Disruption)  \u25cf  Use  Case:  Triggered  by  Kubernetes  itself  during  node  upgrades  or  scaling  down.  \u25cf  Why  It's  Important:  Ensures  graceful  termination  and  restart  elsewhere  without  user  \nimpact.\n \u25cf  Customer  Impact:  Should  be  zero  if  readiness/liveness  probes  and  PDBs  are  correctly  \nconfigured.\n \u25cf  HA  Indicator:  Rolling  disruption  does  not  take  down  the  whole  application.  \n \nHow  to  Know  If  It's  Highly  Available\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help"],
    "reference_answer": "Pod Eviction is a significant chaos scenario because it simulates a 'soft disruption' triggered by Kubernetes itself, typically during routine operations like node upgrades or scaling down. Its importance lies in ensuring graceful termination and restart of pods elsewhere without user impact. For zero customer impact, it is crucial that readiness and liveness probes are correctly configured to manage pod health and traffic flow, and that Pod Disruption Budgets (PDBs) are in place to define the minimum number of available replicas, thereby ensuring that a rolling disruption does not take down the entire application."
  },
  {
    "user_input": "What specific metrics and observations from Krkn telemetry are crucial for quantitatively assessing the high availability of an application after a chaos engineering run?",
    "generated_answer": "The specific metrics and observations from Krkn telemetry crucial for quantitatively assessing the high availability of an application after a chaos engineering run are recovery times, pod reschedule latency, and service downtime. These metrics provide vital insights into the system's ability to recover automatically without manual intervention. They can be obtained through end-of-run data provided by Krkn telemetry.",
    "retrieved_context":["1.  Multiple  Replicas  Exist:  Confirmed  by  checking  kubectl  get  deploy and  seeing  >1  \nreplicas.\n 2.  Pods  Distributed  Across  Nodes/availability  zones:  Using  topologySpreadConstraints or  observing  pod  distribution  in  kubectl  get  pods  \n-o\n \nwide.  3.  Service  Uptime  Remains  Unaffected:  During  chaos  test,  verify  app  availability  (  \nsynthetic\n \nprobes,\n \nPrometheus\n \nalerts,\n \netc).\n 4.  Recovery  Is  Automatic:  No  manual  intervention  needed  to  restore  service.  5.  Krkn  Telemetry  Indicators:  End  of  run  data  includes  recovery  times,  pod  reschedule  \nlatency,\n \nand\n \nservice\n \ndowntime\n \nwhich\n \nare\n \nvital\n \nmetrics\n \nfor\n \nassessing\n \nHA.\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help"],
    "reference_answer": "Krkn telemetry provides vital end-of-run data that is crucial for quantitatively assessing an application's high availability. Key indicators include recovery times, which measure how quickly services are restored post-disruption; pod reschedule latency, indicating the time taken for new pods to become ready and operational; and service downtime, which quantifies any periods of unavailability experienced by the application. These metrics collectively offer a precise measure of the system's resilience and its ability to recover automatically."
  },
  {
    "user_input": "Beyond automatic recovery, what are the key architectural and operational indicators, as described in the text, that confirm an application is highly available in a Kubernetes environment?",
    "generated_answer": "The key architectural and operational indicators that confirm an application is highly available in a Kubernetes environment are: multiple replicas exist, pods are distributed across nodes/availability zones, service uptime remains unaffected during chaos tests, recovery is automatic, and Kraken telemetry indicators show normal metrics. These indicators ensure the application can continue functioning from other replicas across zones/nodes.",
    "retrieved_context": ["1.  Multiple  Replicas  Exist:  Confirmed  by  checking  kubectl  get  deploy and  seeing  >1  \nreplicas.\n 2.  Pods  Distributed  Across  Nodes/availability  zones:  Using  topologySpreadConstraints or  observing  pod  distribution  in  kubectl  get  pods  \n-o\n \nwide.  3.  Service  Uptime  Remains  Unaffected:  During  chaos  test,  verify  app  availability  (  \nsynthetic\n \nprobes,\n \nPrometheus\n \nalerts,\n \netc).\n 4.  Recovery  Is  Automatic:  No  manual  intervention  needed  to  restore  service.  5.  Krkn  Telemetry  Indicators:  End  of  run  data  includes  recovery  times,  pod  reschedule  \nlatency,\n \nand\n \nservice\n \ndowntime\n \nwhich\n \nare\n \nvital\n \nmetrics\n \nfor\n \nassessing\n \nHA.\n\nrecover\n \ngracefully.\n \u25cf  Customer  Impact:  If  all  pods  of  a  service  fail,  user  experience  is  directly  impacted.  \u25cf  HA  Indicator:  Application  can  continue  functioning  from  other  replicas  across  \nzones/nodes.\n \n \n3.  Pod  Eviction  (Soft  Disruption)  \u25cf  Use  Case:  Triggered  by  Kubernetes  itself  during  node  upgrades  or  scaling  down.  \u25cf  Why  It's  Important:  Ensures  graceful  termination  and  restart  elsewhere  without  user  \nimpact.\n \u25cf  Customer  Impact:  Should  be  zero  if  readiness/liveness  probes  and  PDBs  are  correctly  \nconfigured.\n \u25cf  HA  Indicator:  Rolling  disruption  does  not  take  down  the  whole  application.  \n \nHow  to  Know  If  It's  Highly  Available\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:\n\nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario \nKill  a  pod.  :heavy_check_mark:  \nEtcd Kills  a  single/multiple  etcd  replicas.  \n:heavy_check_mark:"],
    "reference_answer": "To confirm an application's high availability in a Kubernetes environment, several architectural and operational indicators are crucial. Architecturally, it's essential to verify that multiple replicas exist for deployments (e.g., `kubectl get deploy` showing >1 replicas) and that pods are distributed across different nodes or availability zones, often achieved using `topologySpreadConstraints` or observed via `kubectl get pods -o wide`. Operationally, during chaos tests, service uptime must remain unaffected, which can be verified through synthetic probes or Prometheus alerts, and crucially, recovery from disruptions must be entirely automatic, requiring no manual intervention."
  },
  {
    "user_input": "How does the 'Single Pod Deletion' scenario specifically validate the resilience mechanisms of Kubernetes, and what is the expected recovery timing for stateless applications in this context?",
    "generated_answer": "The 'Single Pod Deletion' scenario validates the resilience mechanisms of Kubernetes by simulating an unplanned deletion of a single pod, ensuring that the ReplicaSet or Deployment automatically creates a replacement. This typically takes less than 10 seconds for stateless applications. The HA indicator is the automatic rescheduling and readiness of the new pod without manual intervention.",
    "retrieved_context": ["Why  pod  scenarios  are  important:   \n \nUse  Cases  and  Importance  of  Pod-Level  Chaos  Scenarios  \n1.  Single  Pod  Deletion  \u25cf  Use  Case:  Simulates  unplanned  deletion  of  a  single  pod  \u25cf  Why  It's  Important:  Validates  whether  the  ReplicaSet  or  Deployment  automatically  \ncreates\n \na\n \nreplacement.\n \u25cf  Customer  Impact:  Ensures  continuous  service  even  if  a  pod  unexpectedly  crashes.  \u25cf  Recovery  Timing:  Typically  <10  seconds  for  stateless  apps  (seen  in  Krkn  telemetry  \noutput).\n \u25cf  HA  Indicator:  Pod  is  automatically  rescheduled  and  becomes  Ready  without  manual  \nintervention.\n  Kubectl  delete  pod  <pod-name> delete  pod  <pod-name>  Kubectl  get  pods  #  watch  for  new  pods \n2.  Multiple  Pods  Deleted  Simultaneously  \u25cf  Use  Case:  Simulates  a  larger  failure  event,  such  as  a  node  crash  or  AZ  outage.  \u25cf  Why  It's  Important:  Tests  whether  the  system  has  enough  resources  and  policies  to  \nrecover\n\nrecover\n \ngracefully.\n \u25cf  Customer  Impact:  If  all  pods  of  a  service  fail,  user  experience  is  directly  impacted.  \u25cf  HA  Indicator:  Application  can  continue  functioning  from  other  replicas  across  \nzones/nodes.\n \n \n3.  Pod  Eviction  (Soft  Disruption)  \u25cf  Use  Case:  Triggered  by  Kubernetes  itself  during  node  upgrades  or  scaling  down.  \u25cf  Why  It's  Important:  Ensures  graceful  termination  and  restart  elsewhere  without  user  \nimpact.\n \u25cf  Customer  Impact:  Should  be  zero  if  readiness/liveness  probes  and  PDBs  are  correctly  \nconfigured.\n \u25cf  HA  Indicator:  Rolling  disruption  does  not  take  down  the  whole  application.  \n \nHow  to  Know  If  It's  Highly  Available\n\n1.  Multiple  Replicas  Exist:  Confirmed  by  checking  kubectl  get  deploy and  seeing  >1  \nreplicas.\n 2.  Pods  Distributed  Across  Nodes/availability  zones:  Using  topologySpreadConstraints or  observing  pod  distribution  in  kubectl  get  pods  \n-o\n \nwide.  3.  Service  Uptime  Remains  Unaffected:  During  chaos  test,  verify  app  availability  (  \nsynthetic\n \nprobes,\n \nPrometheus\n \nalerts,\n \netc).\n 4.  Recovery  Is  Automatic:  No  manual  intervention  needed  to  restore  service.  5.  Krkn  Telemetry  Indicators:  End  of  run  data  includes  recovery  times,  pod  reschedule  \nlatency,\n \nand\n \nservice\n \ndowntime\n \nwhich\n \nare\n \nvital\n \nmetrics\n \nfor\n \nassessing\n \nHA.\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario"],
    "reference_answer": "The 'Single Pod Deletion' scenario specifically validates whether the ReplicaSet or Deployment automatically creates a replacement pod when an individual pod is unexpectedly deleted. This mechanism ensures continuous service even if a single pod crashes. For stateless applications, the expected recovery timing in this scenario is typically less than 10 seconds, a performance metric often observed and confirmed through Krkn telemetry output."
  },
  {
    "user_input": "What is the primary concern regarding customer impact when 'Multiple Pods Deleted Simultaneously' occurs, and what architectural characteristic helps mitigate this impact to ensure high availability?",
    "generated_answer": "When \"Multiple Pods Deleted Simultaneously\" occurs, the primary concern is that user experience may be directly impacted if all pods of a service fail. This can be mitigated by having enough resources and policies to recover gracefully, such as multiple replicas existing across nodes/availability zones. The architecture should automatically create replacements for failed pods without manual intervention.",
    "retrieved_context": ["Why  pod  scenarios  are  important:   \n \nUse  Cases  and  Importance  of  Pod-Level  Chaos  Scenarios  \n1.  Single  Pod  Deletion  \u25cf  Use  Case:  Simulates  unplanned  deletion  of  a  single  pod  \u25cf  Why  It's  Important:  Validates  whether  the  ReplicaSet  or  Deployment  automatically  \ncreates\n \na\n \nreplacement.\n \u25cf  Customer  Impact:  Ensures  continuous  service  even  if  a  pod  unexpectedly  crashes.  \u25cf  Recovery  Timing:  Typically  <10  seconds  for  stateless  apps  (seen  in  Krkn  telemetry  \noutput).\n \u25cf  HA  Indicator:  Pod  is  automatically  rescheduled  and  becomes  Ready  without  manual  \nintervention.\n  Kubectl  delete  pod  <pod-name> delete  pod  <pod-name>  Kubectl  get  pods  #  watch  for  new  pods \n2.  Multiple  Pods  Deleted  Simultaneously  \u25cf  Use  Case:  Simulates  a  larger  failure  event,  such  as  a  node  crash  or  AZ  outage.  \u25cf  Why  It's  Important:  Tests  whether  the  system  has  enough  resources  and  policies  to  \nrecover\n\nrecover\n \ngracefully.\n \u25cf  Customer  Impact:  If  all  pods  of  a  service  fail,  user  experience  is  directly  impacted.  \u25cf  HA  Indicator:  Application  can  continue  functioning  from  other  replicas  across  \nzones/nodes.\n \n \n3.  Pod  Eviction  (Soft  Disruption)  \u25cf  Use  Case:  Triggered  by  Kubernetes  itself  during  node  upgrades  or  scaling  down.  \u25cf  Why  It's  Important:  Ensures  graceful  termination  and  restart  elsewhere  without  user  \nimpact.\n \u25cf  Customer  Impact:  Should  be  zero  if  readiness/liveness  probes  and  PDBs  are  correctly  \nconfigured.\n \u25cf  HA  Indicator:  Rolling  disruption  does  not  take  down  the  whole  application.  \n \nHow  to  Know  If  It's  Highly  Available\n\n1.  Multiple  Replicas  Exist:  Confirmed  by  checking  kubectl  get  deploy and  seeing  >1  \nreplicas.\n 2.  Pods  Distributed  Across  Nodes/availability  zones:  Using  topologySpreadConstraints or  observing  pod  distribution  in  kubectl  get  pods  \n-o\n \nwide.  3.  Service  Uptime  Remains  Unaffected:  During  chaos  test,  verify  app  availability  (  \nsynthetic\n \nprobes,\n \nPrometheus\n \nalerts,\n \netc).\n 4.  Recovery  Is  Automatic:  No  manual  intervention  needed  to  restore  service.  5.  Krkn  Telemetry  Indicators:  End  of  run  data  includes  recovery  times,  pod  reschedule  \nlatency,\n \nand\n \nservice\n \ndowntime\n \nwhich\n \nare\n \nvital\n \nmetrics\n \nfor\n \nassessing\n \nHA.\n\nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario \nKill  a  pod.  :heavy_check_mark:  \nEtcd Kills  a  single/multiple  etcd  replicas.  \n:heavy_check_mark:"],
    "reference_answer": "The primary concern regarding customer impact when 'Multiple Pods Deleted Simultaneously' occurs is that if all pods of a service fail, the user experience is directly impacted, potentially leading to service unavailability. This significant impact can be mitigated and high availability ensured if the application is designed with redundancy, allowing it to continue functioning from other replicas that are distributed across different zones or nodes, preventing a single point of failure from taking down the entire service."
  },
  {
    "user_input": "Describe the role of `topologySpreadConstraints` in achieving high availability and how their effective implementation can be verified using standard Kubernetes commands.",
    "generated_answer": "`topologySpreadConstraints` is a feature in Kubernetes that helps achieve high availability by ensuring pods are distributed across nodes and availability zones, reducing the impact of node failures. Its effective implementation can be verified using standard Kubernetes commands like `kubectl get pods -o wide`, which displays pod distribution information. This allows administrators to monitor and validate the topology spread constraints configuration.",
    "retrieved_context": ["Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario \nKill  a  pod.  :heavy_check_mark:  \nEtcd Kills  a  single/multiple  etcd  replicas.  \n:heavy_check_mark:\n\n1.  Multiple  Replicas  Exist:  Confirmed  by  checking  kubectl  get  deploy and  seeing  >1  \nreplicas.\n 2.  Pods  Distributed  Across  Nodes/availability  zones:  Using  topologySpreadConstraints or  observing  pod  distribution  in  kubectl  get  pods  \n-o\n \nwide.  3.  Service  Uptime  Remains  Unaffected:  During  chaos  test,  verify  app  availability  (  \nsynthetic\n \nprobes,\n \nPrometheus\n \nalerts,\n \netc).\n 4.  Recovery  Is  Automatic:  No  manual  intervention  needed  to  restore  service.  5.  Krkn  Telemetry  Indicators:  End  of  run  data  includes  recovery  times,  pod  reschedule  \nlatency,\n \nand\n \nservice\n \ndowntime\n \nwhich\n \nare\n \nvital\n \nmetrics\n \nfor\n \nassessing\n \nHA."],
    "reference_answer": "`topologySpreadConstraints` play a crucial role in achieving high availability by ensuring that pods are distributed evenly across different failure domains, such as nodes or availability zones. This prevents a single point of failure from impacting all replicas of an application. The effective implementation and resulting distribution can be observed using standard Kubernetes commands like `kubectl get pods -o wide`, which displays the node on which each pod is running, allowing an administrator to visually confirm the desired spread across the cluster's topology."
  },
  {
    "user_input": "In the context of chaos engineering, what does 'Recovery Is Automatic' signify as a high availability indicator, and why is the absence of manual intervention considered critical for true HA?",
    "generated_answer": "\"Recovery Is Automatic\" signifies that the system can recover from a failure without manual intervention, which is critical for true high availability (HA) because it ensures continuous service even in the face of unexpected outages. The absence of manual intervention allows for quick and efficient recovery, minimizing downtime and customer impact. This indicator verifies whether the system's design can handle failures automatically, making it an essential aspect of HA testing.",
    "retrieved_context": ["1.  Multiple  Replicas  Exist:  Confirmed  by  checking  kubectl  get  deploy and  seeing  >1  \nreplicas.\n 2.  Pods  Distributed  Across  Nodes/availability  zones:  Using  topologySpreadConstraints or  observing  pod  distribution  in  kubectl  get  pods  \n-o\n \nwide.  3.  Service  Uptime  Remains  Unaffected:  During  chaos  test,  verify  app  availability  (  \nsynthetic\n \nprobes,\n \nPrometheus\n \nalerts,\n \netc).\n 4.  Recovery  Is  Automatic:  No  manual  intervention  needed  to  restore  service.  5.  Krkn  Telemetry  Indicators:  End  of  run  data  includes  recovery  times,  pod  reschedule  \nlatency,\n \nand\n \nservice\n \ndowntime\n \nwhich\n \nare\n \nvital\n \nmetrics\n \nfor\n \nassessing\n \nHA.\n\nrecover\n \ngracefully.\n \u25cf  Customer  Impact:  If  all  pods  of  a  service  fail,  user  experience  is  directly  impacted.  \u25cf  HA  Indicator:  Application  can  continue  functioning  from  other  replicas  across  \nzones/nodes.\n \n \n3.  Pod  Eviction  (Soft  Disruption)  \u25cf  Use  Case:  Triggered  by  Kubernetes  itself  during  node  upgrades  or  scaling  down.  \u25cf  Why  It's  Important:  Ensures  graceful  termination  and  restart  elsewhere  without  user  \nimpact.\n \u25cf  Customer  Impact:  Should  be  zero  if  readiness/liveness  probes  and  PDBs  are  correctly  \nconfigured.\n \u25cf  HA  Indicator:  Rolling  disruption  does  not  take  down  the  whole  application.  \n \nHow  to  Know  If  It's  Highly  Available\n\nWhy  pod  scenarios  are  important:   \n \nUse  Cases  and  Importance  of  Pod-Level  Chaos  Scenarios  \n1.  Single  Pod  Deletion  \u25cf  Use  Case:  Simulates  unplanned  deletion  of  a  single  pod  \u25cf  Why  It's  Important:  Validates  whether  the  ReplicaSet  or  Deployment  automatically  \ncreates\n \na\n \nreplacement.\n \u25cf  Customer  Impact:  Ensures  continuous  service  even  if  a  pod  unexpectedly  crashes.  \u25cf  Recovery  Timing:  Typically  <10  seconds  for  stateless  apps  (seen  in  Krkn  telemetry  \noutput).\n \u25cf  HA  Indicator:  Pod  is  automatically  rescheduled  and  becomes  Ready  without  manual  \nintervention.\n  Kubectl  delete  pod  <pod-name> delete  pod  <pod-name>  Kubectl  get  pods  #  watch  for  new  pods \n2.  Multiple  Pods  Deleted  Simultaneously  \u25cf  Use  Case:  Simulates  a  larger  failure  event,  such  as  a  node  crash  or  AZ  outage.  \u25cf  Why  It's  Important:  Tests  whether  the  system  has  enough  resources  and  policies  to  \nrecover\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:"],
    "reference_answer": "In chaos engineering, 'Recovery Is Automatic' as a high availability indicator signifies that the system is designed to self-heal and restore service without any human intervention after a disruption. The absence of manual intervention is considered critical for true HA because it demonstrates the system's inherent resilience and automation capabilities. Manual intervention introduces delays, increases the potential for human error, and indicates a dependency on operational teams rather than robust, self-managing infrastructure, undermining the goal of continuous service availability."
  },
  {
    "user_input": "What is the primary purpose of the `pod_disruption_scenarios` section within a Krkn configuration, and how is a specific scenario file referenced?",
    "generated_answer": "The primary purpose of the `pod_disruption_scenarios` section within a Krkn configuration is to define chaos scenarios that disrupt pods. A specific scenario file is referenced by its path, as shown in the example where `path/to/scenario.yaml` is referenced. This YAML file defines the disruption rules and settings for the pod chaos scenario.",
    "retrieved_context": ["None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*"],
    "reference_answer": "The `pod_disruption_scenarios` section in a Krkn configuration is used to define and include specific pod chaos scenarios. A scenario file is referenced by providing its `path/to/scenario.yaml` within this section, allowing Krkn to execute the disruption defined in that file."
  },
  {
    "user_input": "How can a user leverage the provided schema file to enhance their experience when creating a Krkn scenario configuration in an IDE?",
    "generated_answer": "To leverage the provided schema file, a user can update the yaml-language-server reference in their scenario configuration file to point to the schema file. This will enable code completion and documentation for available options in the IDE. The updated line would be: `# yaml-language-server: $schema=../path/to/plugin.schema.json`.",
    "retrieved_context": ["None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*"],
    "reference_answer": "Users can enhance their experience by adjusting the schema reference in their scenario file to point to the `plugin.schema.json` file (e.g., `yaml-language-server: $schema=../plugin.schema.json`). This integration provides valuable features like code completion and documentation for available options directly within their IDE."
  },
  {
    "user_input": "Based on the example configuration, which specific Kubernetes component is targeted for disruption, and what criteria are used to select its pods?",
    "generated_answer": "The specific Kubernetes component targeted for disruption is \"Etcd\" and its replicas. The criteria used to select its pods are based on the provided configuration options, including namespace pattern, label selector, and disruption count.",
    "retrieved_context": ["Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:\n\nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario \nKill  a  pod.  :heavy_check_mark:  \nEtcd Kills  a  single/multiple  etcd  replicas.  \n:heavy_check_mark:\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario"],
    "reference_answer": "In the example configuration, the `kill-pods` scenario targets the `kube-scheduler` component. It selects pods by looking for those within the `kube-system` namespace (specified by `namespace_pattern: ^kube-system$`) that also possess the label `k8s-app=kube-scheduler` (specified by `label_selector`)."
  },
  {
    "user_input": "What is the function of the `krkn_pod_recovery_time` parameter in a Krkn pod disruption scenario, and what is its value in the provided example?",
    "generated_answer": "The `krkn_pod_recovery_time` parameter sets the expected time for a pod to recover after being disrupted, and its value in the provided example is 120 seconds. This means that the scenario will fail if the pods do not recover within this time frame. The value can be adjusted based on the specific requirements of the chaos testing scenario.",
    "retrieved_context": ["Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy"],
    "reference_answer": "The `krkn_pod_recovery_time` parameter specifies the duration, in seconds, that Krkn will wait for a disrupted pod to recover. In the provided example, its value is set to `120`, indicating a 120-second recovery period."
  },
  {
    "user_input": "Beyond a general 'basic pod scenario,' what are some of the critical Kubernetes or OpenShift components for which Krkn offers pre-defined chaos scenarios, and are they currently functional?",
    "generated_answer": "Krkn offers pre-defined chaos scenarios for critical Kubernetes and OpenShift components such as pod disruption, container runtime disruptions, node network disruptions, and more. These scenarios are currently functional and can be run using the krknctl command with specific parameters to target namespaces, pods, and labels. The available scenario options can also be viewed by running `krknctl run pod-scenarios --help`.",
    "retrieved_context": ["None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:"],
    "reference_answer": "Krkn offers pre-defined chaos scenarios for critical components such as Etcd, Kube ApiServer, ApiServer, Prometheus, and random pods running in OpenShift system namespaces. According to the 'Working' column in the provided table, all these listed scenarios are currently functional."
  },
  {
    "user_input": "If a user wanted to specifically target the Kubernetes API server for a chaos experiment, which Krkn scenario would be appropriate, and what action would it perform?",
    "generated_answer": "The Krkn scenario to specifically target the Kubernetes API server for a chaos experiment is \"ApiServer Kills\". This scenario kills a single or multiple kube-apiserver replicas, disrupting the API server's functionality. The action performed by this scenario is to terminate the API server pods.",
    "retrieved_context": ["None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nKube  ApiServer Kills  a  single/multiple  kube-apiserver  replicas.  \n:heavy_check_mark:  \nApiServer Kills  a  single/multiple  apiserver  replicas.  \n:heavy_check_mark:  \nPrometheus Kills  a  single/multiple  prometheus  replicas.  \n:heavy_check_mark:  \nOpenShift  System  Pods \nKills  random  pods  running  in  the  OpenShift  system  namespaces.  \n:heavy_check_mark:"],
    "reference_answer": "To target the Kubernetes API server, the 'Kube ApiServer' scenario would be appropriate. This scenario is designed to kill either a single or multiple replicas of the kube-apiserver component."
  },
  {
    "user_input": "How does the 'OpenShift System Pods' chaos scenario differ in its targeting approach compared to component-specific scenarios like 'Etcd' or 'Prometheus'?",
    "generated_answer": "The 'OpenShift System Pods' chaos scenario targets all system pods across all namespaces, whereas component-specific scenarios like 'Etcd' or 'Prometheus' target a specific namespace and pod label. This allows for more targeted disruption of specific components. The targeting approach in OpenShift System Pods is more broad compared to the other scenarios.",
    "retrieved_context": ["None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*"],
    "reference_answer": "The 'OpenShift System Pods' scenario targets random pods running across various OpenShift system namespaces, providing a broader, less specific disruption. In contrast, component-specific scenarios like 'Etcd' or 'Prometheus' precisely target replicas of those named components, focusing disruption on a particular service."
  },
  {
    "user_input": "What is the purpose of the `id` field within a Krkn scenario configuration, as demonstrated by the `kill-pods` example?",
    "generated_answer": "The `id` field within a Krkn scenario configuration, as demonstrated by the `kill-pods` example, is used to uniquely identify the scenario. It does not have any functional purpose other than identification.",
    "retrieved_context": ["Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*"],
    "reference_answer": "The `id` field, exemplified by `kill-pods`, serves as a unique identifier for a specific chaos scenario defined within the Krkn configuration file. It provides a distinct name for the scenario being executed."
  },
  {
    "user_input": "Can the `kill-pods` scenario, as configured in the example, disrupt pods located in namespaces other than `kube-system`?",
    "generated_answer": "The `kill-pods` scenario can disrupt pods in namespaces other than `kube-system` if the `--namespace` parameter is set to a value that supports regex (e.g. `openshift-*`). This allows for disruption of pods across multiple namespaces, including those not specifically listed as system namespaces.",
    "retrieved_context": ["Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nKube  ApiServer Kills  a  single/multiple  kube-apiserver  replicas.  \n:heavy_check_mark:  \nApiServer Kills  a  single/multiple  apiserver  replicas.  \n:heavy_check_mark:  \nPrometheus Kills  a  single/multiple  prometheus  replicas.  \n:heavy_check_mark:  \nOpenShift  System  Pods \nKills  random  pods  running  in  the  OpenShift  system  namespaces.  \n:heavy_check_mark:\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:"],
    "reference_answer": "No, the `kill-pods` scenario, as configured in the example, cannot disrupt pods outside of the `kube-system` namespace. This is explicitly controlled by the `namespace_pattern: ^kube-system$` setting, which restricts the scenario's scope to that specific namespace."
  },
  {
    "user_input": "Describe the hierarchical structure for defining chaos scenarios within the top-level `kraken` configuration block.",
    "generated_answer": "The hierarchical structure for defining chaos scenarios within the top-level `kraken` configuration block is as follows:\n\n1. `chaos_scenarios`\n2. `pod_disruption_scenarios`\n3. `- path/to/scenario.yaml` (specific scenario file)\n\nThis structure allows for a clear and organized definition of chaos scenarios, with each scenario being a separate YAML file under the `pod_disruption_scenarios` block.",
    "retrieved_context": ["None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\n1.  Multiple  Replicas  Exist:  Confirmed  by  checking  kubectl  get  deploy and  seeing  >1  \nreplicas.\n 2.  Pods  Distributed  Across  Nodes/availability  zones:  Using  topologySpreadConstraints or  observing  pod  distribution  in  kubectl  get  pods  \n-o\n \nwide.  3.  Service  Uptime  Remains  Unaffected:  During  chaos  test,  verify  app  availability  (  \nsynthetic\n \nprobes,\n \nPrometheus\n \nalerts,\n \netc).\n 4.  Recovery  Is  Automatic:  No  manual  intervention  needed  to  restore  service.  5.  Krkn  Telemetry  Indicators:  End  of  run  data  includes  recovery  times,  pod  reschedule  \nlatency,\n \nand\n \nservice\n \ndowntime\n \nwhich\n \nare\n \nvital\n \nmetrics\n \nfor\n \nassessing\n \nHA."],
    "reference_answer": "Within the `kraken` configuration block, chaos scenarios are organized under the `chaos_scenarios` key. This key contains a list, where each item is a `pod_disruption_scenarios` entry, which in turn specifies the `path/to/scenario.yaml` file containing the detailed configuration for a particular pod disruption."
  }
],
"email": "tgangise@redhat.com"
}