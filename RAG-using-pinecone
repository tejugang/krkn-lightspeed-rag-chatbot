from openai import OpenAI
from pinecone import Pinecone, ServerlessSpec
import numpy as np
import os
import pdfplumber  
from tqdm import tqdm

openai_api_key = "open-AI-API-key"      
pinecone_api_key = "pinecone-api-key"     
index_name = "krkn-lightspeed-rag-demo" 

# initialize openAI and pinecone
client = OpenAI(api_key=openai_api_key)

pc = Pinecone(api_key=pinecone_api_key)

# create index if it does not exist
existing_indexes = pc.list_indexes().names()
if index_name not in existing_indexes:
    pc.create_index(
        name=index_name,
        dimension=1536,
        metric="cosine",
        spec=ServerlessSpec(
            cloud="aws",
            region="us-east-1"
        )
    )

index = pc.Index(index_name)

# load pdf and convert text into chunks
def load_pdf_chunks(path, chunk_size=300):
    chunks = []
    with pdfplumber.open(path) as pdf:
        for page in pdf.pages:
            text = page.extract_text()
            if text:
                for i in range(0, len(text), chunk_size):
                    chunks.append(text[i : i + chunk_size])
    return chunks

# embed and store chunks
def embed_and_store(chunks):
    for i, chunk in enumerate(tqdm(chunks)):
        embedding = client.embeddings.create(input=chunk, model="text-embedding-ada-002").data[0].embedding
        index.upsert([(f"chunk-{i}", embedding, {"text": chunk})])

# retrieve relavent context from pinecone
def retrieve_context(question, k=3):
    question_embedding = client.embeddings.create(input=question, model="text-embedding-ada-002").data[0].embedding
    results = index.query(vector=question_embedding, top_k=k, include_metadata=True)
    return " ".join([match["metadata"]["text"] for match in results["matches"]])

# generate answer from the context
def generate_answer(question, context):
    prompt = f"Use the following context to answer the question.\nContext: {context}\nQuestion: {question}\nAnswer:"
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
    )
    return response.choices[0].message.content.strip()

if __name__ == "__main__":
    stats = index.describe_index_stats()
    total_vectors = stats.get("total_vector_count", 0)
    if total_vectors == 0:
#set pdf path
        chunks = load_pdf_chunks("pdf-path")
        embed_and_store(chunks)

    user_question = input("Ask a question: ")
    context = retrieve_context(user_question)
    answer = generate_answer(user_question, context)
    print("Answer:", answer)
