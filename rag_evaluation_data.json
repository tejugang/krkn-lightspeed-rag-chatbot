{
  "items": [
  {
    "user_input": "What is the primary objective of the 'Pod Scenarios' feature within Krkn-hub on a Kubernetes/OpenShift cluster?",
    "generated_answer": "  I  don't  know  the  answer.",
    "retrieved_context": "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:",
    "time_taken_seconds": 2528.16
  },
  {
    "user_input": "How can Cerberus be integrated with Krkn-hub's pod scenarios to monitor the cluster and determine the success or failure of a chaos injection?",
    "generated_answer": "  I'm just an AI and don't know the answer to your question. You can use Cerberus with Krkn-hub's pod scenarios to monitor the cluster and determine the success or failure of a chaos injection by referring to the provided context and using the `podman` command to run the scenario and log the output. However, I don't have access to the specific details of your scenario configuration or the output of the `podman` command, so I cannot provide you with the exact steps to take.",
    "retrieved_context": "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:",
    "time_taken_seconds": 85.17
  },
  {
    "user_input": "What is the standard Podman command structure for initiating a pod disruption scenario with Krkn-hub, including how to provide the kube config and enable host environment variables?",
    "generated_answer": " The standard Podman command structure for initiating a pod disruption scenario with Krkn-hub, including how to provide the Kube config and enable host environment variables, is as follows:\n$ podman run --name=<container_name> --net=host -v <path-to-kube-config>:/home/krkn/.kube/config:Z --dockercfg /home/krkn/.docker/config.json -e KRKN_HUB_ENABLED=true -e KRKN_LOGGING_LEVEL=info -d containers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\nThe above command structure can be used to initiate a pod disruption scenario with Krkn-hub, including how to provide the Kube config and enable host environment variables. The command uses Podman's run command to create a new container with the specified name and network configuration, and mounts the Kube config file at the /home/krkn/.kube/config path. The -e flag is used to set environment variables for KRKN_HUB_",
    "retrieved_context": "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy  \nNote  \u2013env-host:  This  option  is  not  available  with  the  remote  Podman  client,  including  Mac  and  \nWindows\n \n(excluding\n \nWSL2)\n \nmachines.\n \nWithout\n \nthe\n \n\u2013env-host\n \noption\n \nyou\u2019ll\n \nhave\n \nto\n \nset\n \neach\n \nenviornment\n \nvariable\n \non\n \nthe\n \npodman\n \ncommand\n \nline\n \nlike\n \n-e\n \n<VARIABLE>=<value>\n \n$  docker  run  $(./get_docker_params.sh)  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n OR   $  docker  run  -e  <VARIABLE>=<value>  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n  $  docker  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  docker  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario",
    "time_taken_seconds": 101.44
  },
  {
    "user_input": "After a Krkn-hub pod scenario has been initiated, what commands can be used with both Podman and Docker to monitor its ongoing logs and to retrieve its final exit code for pass/fail determination?",
    "generated_answer": " To monitor the ongoing logs of a Krkn-hub pod scenario using Podman, you can use the `-f` option to follow the container's logs and retrieve the final exit code using the `podman inspect` command. Here are the commands you can use:\n$ podman run --name=<container_name> --net=host -v <path-to-kube-config>:/home/krkn/.kube/config:Z -d containers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios $ podman logs -f <container_name or container_id> # Streams Kraken logs $ podman inspect <container-name or container-id> --format \"{{.State.ExitCode}}\" # Retrieve the final exit code for pass/fail determination\nNote that you need to set the `--env-host=true` option in the Podman command to enable the `-d` flag, which allows you to retrieve the final exit code of the container. Additionally, you can use the `krknctl run pod-scenarios` command to run the scenario and monitor its progress using the",
    "retrieved_context": "Outputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy  \nNote  \u2013env-host:  This  option  is  not  available  with  the  remote  Podman  client,  including  Mac  and  \nWindows\n \n(excluding\n \nWSL2)\n \nmachines.\n \nWithout\n \nthe\n \n\u2013env-host\n \noption\n \nyou\u2019ll\n \nhave\n \nto\n \nset\n \neach\n \nenviornment\n \nvariable\n \non\n \nthe\n \npodman\n \ncommand\n \nline\n \nlike\n \n-e\n \n<VARIABLE>=<value>\n \n$  docker  run  $(./get_docker_params.sh)  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n OR   $  docker  run  -e  <VARIABLE>=<value>  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n  $  docker  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  docker  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\n$  docker  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  docker  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
    "time_taken_seconds": 90.55
  },
  {
    "user_input": "What is a significant limitation of the `--env-host` option when running Krkn-hub scenarios with Podman on certain client types, and how should environment variables be managed in such cases?",
    "generated_answer": " The `--env-host` option is not available when running Krkn-hub scenarios with Podman on certain client types, including Mac and Windows (excluding WSL2). When using Podman without the `--env-host` option, environment variables must be managed by setting them on the command line or in a configuration file.",
    "retrieved_context": "Outputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy  \nNote  \u2013env-host:  This  option  is  not  available  with  the  remote  Podman  client,  including  Mac  and  \nWindows\n \n(excluding\n \nWSL2)\n \nmachines.\n \nWithout\n \nthe\n \n\u2013env-host\n \noption\n \nyou\u2019ll\n \nhave\n \nto\n \nset\n \neach\n \nenviornment\n \nvariable\n \non\n \nthe\n \npodman\n \ncommand\n \nline\n \nlike\n \n-e\n \n<VARIABLE>=<value>\n \n$  docker  run  $(./get_docker_params.sh)  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n OR   $  docker  run  -e  <VARIABLE>=<value>  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n  $  docker  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  docker  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #\n\nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:  \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-custom-metrics-profile>:/home/krkn/kraken/config/metrics-aggregated.yaml\n \n-v\n \n<path-to-custom-alerts-profile>:/home/krkn/kraken/config/alerts\n \n-v\n \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:container-scenarios\n \nCopy\n\nNone \n None \nTip  Because  the  container  runs  with  a  non-root  user,  ensure  the  kube  config  is  globally  readable  \nbefore\n \nmounting\n \nit\n \nin\n \nthe\n \ncontainer.\n \nYou\n \ncan\n \nachieve\n \nthis\n \nwith\n \nthe\n \nfollowing\n \ncommands:\n \nkubectl\n \nconfig\n \nview\n \n--flatten\n \n>\n \n~/kubeconfig\n \n&&\n \nchmod\n \n444\n \n~/kubeconfig\n \n&&\n \ndocker\n \nrun\n \n$(./get_docker_params.sh)\n \n--name=<container_name>\n \n--net=host\n \n-v\n \n~kubeconfig:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:<scenario>\n \nSupported  parameters  The  following  environment  variables  can  be  set  on  the  host  running  the  container  to  tweak  the  \nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
    "time_taken_seconds": 80.78
  },
  {
    "user_input": "Why is it crucial to adjust the permissions of the kube config file before mounting it into the Krkn-hub container, and what specific commands are recommended to achieve this?",
    "generated_answer": " The command to mount the kube config file into the Krkn-hub container is:\n```\ndocker run -v ~kubeconfig:/home/krkn/.kube/config:Z --name=<container_name> --net=host -d containers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n```\nExplanation:\n* `-v ~kubeconfig:/home/krkn/.kube/config:Z` mounts the `~kubeconfig` directory (i.e., the home directory of the user running the container) as a volume into the container, with the name `~kubeconfig`. This allows the container to read the kube config file in that directory.\n* `--name=<container_name>` sets the name of the container to `<container_name>`.\n* `--net=host` tells Docker to use the host's network stack, rather than a built-in network stack. This is necessary because the container runs with a non-root user, and therefore cannot read the kube config file directly.\n* `-d containers.krkn-chaos.dev/",
    "retrieved_context": "None \n None \nTip  Because  the  container  runs  with  a  non-root  user,  ensure  the  kube  config  is  globally  readable  \nbefore\n \nmounting\n \nit\n \nin\n \nthe\n \ncontainer.\n \nYou\n \ncan\n \nachieve\n \nthis\n \nwith\n \nthe\n \nfollowing\n \ncommands:\n \nkubectl\n \nconfig\n \nview\n \n--flatten\n \n>\n \n~/kubeconfig\n \n&&\n \nchmod\n \n444\n \n~/kubeconfig\n \n&&\n \ndocker\n \nrun\n \n$(./get_docker_params.sh)\n \n--name=<container_name>\n \n--net=host\n \n-v\n \n~kubeconfig:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:<scenario>\n \nSupported  parameters  The  following  environment  variables  can  be  set  on  the  host  running  the  container  to  tweak  the  \nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:  \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-custom-metrics-profile>:/home/krkn/kraken/config/metrics-aggregated.yaml\n \n-v\n \n<path-to-custom-alerts-profile>:/home/krkn/kraken/config/alerts\n \n-v\n \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:container-scenarios\n \nCopy\n\nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy  \nNote  \u2013env-host:  This  option  is  not  available  with  the  remote  Podman  client,  including  Mac  and  \nWindows\n \n(excluding\n \nWSL2)\n \nmachines.\n \nWithout\n \nthe\n \n\u2013env-host\n \noption\n \nyou\u2019ll\n \nhave\n \nto\n \nset\n \neach\n \nenviornment\n \nvariable\n \non\n \nthe\n \npodman\n \ncommand\n \nline\n \nlike\n \n-e\n \n<VARIABLE>=<value>\n \n$  docker  run  $(./get_docker_params.sh)  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n OR   $  docker  run  -e  <VARIABLE>=<value>  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n  $  docker  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  docker  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #",
    "time_taken_seconds": 133.19
  },
  {
    "user_input": "How can environment variables be passed to a Krkn-hub scenario container to customize its behavior, detailing both the host-based and command-line methods?",
    "generated_answer": " \nYou can set environment variables on the host running the container using the \u2013env-host option, or on the command line like -e <VARIABLE>=<value>. Shell commands are supported.",
    "retrieved_context": "Outputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy  \nNote  \u2013env-host:  This  option  is  not  available  with  the  remote  Podman  client,  including  Mac  and  \nWindows\n \n(excluding\n \nWSL2)\n \nmachines.\n \nWithout\n \nthe\n \n\u2013env-host\n \noption\n \nyou\u2019ll\n \nhave\n \nto\n \nset\n \neach\n \nenviornment\n \nvariable\n \non\n \nthe\n \npodman\n \ncommand\n \nline\n \nlike\n \n-e\n \n<VARIABLE>=<value>\n \n$  docker  run  $(./get_docker_params.sh)  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n OR   $  docker  run  -e  <VARIABLE>=<value>  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n  $  docker  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  docker  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #\n\nNone \n None \nTip  Because  the  container  runs  with  a  non-root  user,  ensure  the  kube  config  is  globally  readable  \nbefore\n \nmounting\n \nit\n \nin\n \nthe\n \ncontainer.\n \nYou\n \ncan\n \nachieve\n \nthis\n \nwith\n \nthe\n \nfollowing\n \ncommands:\n \nkubectl\n \nconfig\n \nview\n \n--flatten\n \n>\n \n~/kubeconfig\n \n&&\n \nchmod\n \n444\n \n~/kubeconfig\n \n&&\n \ndocker\n \nrun\n \n$(./get_docker_params.sh)\n \n--name=<container_name>\n \n--net=host\n \n-v\n \n~kubeconfig:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:<scenario>\n \nSupported  parameters  The  following  environment  variables  can  be  set  on  the  host  running  the  container  to  tweak  the  \nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
    "time_taken_seconds": 99.82
  },
  {
    "user_input": "What is the function of the `NAMESPACE` parameter in Krkn-hub pod scenarios, and what is its default value, including its support for advanced matching?",
    "generated_answer": " The `NAMESPACE` parameter in Krkn-hub pod scenarios refers to the targeted namespace in the cluster, which can be specified using a regular expression pattern. By default, it is set to `openshift-*` (i.e., all OpenShift namespaces).\nIn addition, you can use any global variable listed in the context section, such as `POD_LABEL`, `NAME_PATTERN`, and `KILL_TIMEOUT`. These variables can be set using the `--<parameter>:<value>` option or by exporting them using the `export` command.",
    "retrieved_context": "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario",
    "time_taken_seconds": 78.04
  },
  {
    "user_input": "Explain the interplay between the `POD_LABEL` and `NAME_PATTERN` parameters in determining which pods are targeted for disruption, and what their default behaviors are.",
    "generated_answer": " \nThe  `POD_LABEL` and `NAME_PATTERN` parameters work together to determine which pods are targeted for disruption in a Kubernetes/OpenShift cluster. The `POD_LABEL` parameter specifies the label of the pods to target, while the `NAME_PATTERN` parameter specifies the namespace in which to find the pods matching the label. If the `POD_LABEL` parameter is not specified, the `NAME_PATTERN` parameter is used to match pods in a specific namespace.\nIn summary, the `POD_LABEL` and `NAME_PATTERN` parameters are used together to determine which pods are targeted for disruption in a Kubernetes/OpenShift cluster, with the `POD_LABEL` parameter specifying the label of the pods to target and the `NAME_PATTERN` parameter specifying the namespace in which to find the pods matching the label.",
    "retrieved_context": "Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
    "time_taken_seconds": 95.02
  },
  {
    "user_input": "What do the `DISRUPTION_COUNT`, `KILL_TIMEOUT`, and `EXPECTED_RECOVERY_TIME` parameters control in a Krkn-hub pod scenario, and what are their default values?",
    "generated_answer": " \nThe  `DISRUPTION_COUNT`, `KILL_TIMEOUT`, and `EXPECTED_RECOVERY_TIME` parameters control the behavior of a Krkn-hub pod scenario. Here are their default values:\n\n* `DISRUPTION_COUNT`: 1 (i.e., disrupt one pod)\n* `KILL_TIMEOUT`: 180 seconds (i.e., wait for the target pods to be removed within this time frame)\n* `EXPECTED_RECOVERY_TIME`: 120 seconds (i.e., fail the scenario if the disrupted pods do not recover within this time frame)\n\nIn summary, these parameters determine how many pods are disrupted, how long to wait for them to be removed, and how long to expect them to recover before failing the scenario.",
    "retrieved_context": "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
    "time_taken_seconds": 99.7
  },
  {
    "user_input": "Beyond specific namespace targeting, how can the `NAMESPACE` environment variable be configured to randomly disrupt pods in OpenShift system namespaces, and what additional mode can be enabled for continuous reliability testing?",
    "generated_answer": " \nThe `NAMESPACE` environment variable can be configured to randomly disrupt pods in OpenShift system namespaces by setting the variable to `openshift-.*`. This will pick and disrupt pods randomly in the specified namespace. Additionally, the `DAEMON_MODE` can be enabled for continuous reliability testing.\nNote: In case of using custom metrics profile or alerts profile when `CAPTURE_METRICS` or `ENABLE_ALERTS` is enabled, the metrics profile from the host on which the container is running can be mounted and used to disrupt the pods. The metrics profile can be configured by setting the `metrics-profile` field in the OpenShift cluster configuration file.\nExample:\n```bash\nscenario/faults being injected:\nexample:\nexport <parameter_name>=<value>\nOR on the command line like example:\n\n-e <VARIABLE>=<value>\nSee list of variables that apply to all scenarios here that can be used/set in addition to these scenario-specific variables.\n\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "retrieved_context": "Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:\n\nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
    "time_taken_seconds": 95.54
  },
  {
    "user_input": "When `CAPTURE_METRICS` or `ENABLE_ALERTS` are active, how should custom metrics and alerts profiles be provided to the Krkn-hub container, including the specific internal paths for mounting?",
    "generated_answer": "\nYou  don't know the answer.",
    "retrieved_context": "the\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:  \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-custom-metrics-profile>:/home/krkn/kraken/config/metrics-aggregated.yaml\n \n-v\n \n<path-to-custom-alerts-profile>:/home/krkn/kraken/config/alerts\n \n-v\n \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:container-scenarios\n \nCopy\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:\n\nNone \n None \nTip  Because  the  container  runs  with  a  non-root  user,  ensure  the  kube  config  is  globally  readable  \nbefore\n \nmounting\n \nit\n \nin\n \nthe\n \ncontainer.\n \nYou\n \ncan\n \nachieve\n \nthis\n \nwith\n \nthe\n \nfollowing\n \ncommands:\n \nkubectl\n \nconfig\n \nview\n \n--flatten\n \n>\n \n~/kubeconfig\n \n&&\n \nchmod\n \n444\n \n~/kubeconfig\n \n&&\n \ndocker\n \nrun\n \n$(./get_docker_params.sh)\n \n--name=<container_name>\n \n--net=host\n \n-v\n \n~kubeconfig:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:<scenario>\n \nSupported  parameters  The  following  environment  variables  can  be  set  on  the  host  running  the  container  to  tweak  the  \nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
    "time_taken_seconds": 78.26
  },
  {
    "user_input": "When executing a `pod-scenarios` run with `krknctl`, what are the different mechanisms available for precisely identifying the target pods for disruption, and how do they interact?",
    "generated_answer": "  I'm sorry, but the text you provided doesn't contain enough information to answer your question. Please provide more context or clarify your inquiry so that I can assist you better.",
    "retrieved_context": "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:",
    "time_taken_seconds": 83.99
  },
  {
    "user_input": "Describe the two critical timeout parameters in `krknctl run pod-scenarios` and explain their distinct roles in determining the scenario's outcome.",
    "generated_answer": " \nThe  two  critical  timeout  parameters  in   `krknctl run pod-scenarios` are --kill-timeout and --expected-recovery-time. The --kill-timeout specifies the amount of time to wait for the target pods to be removed, while --expected-recovery-time determines whether the pod disrupted does not recover within the timeout set. These parameters play distinct roles in determining the scenario's outcome, with the kill timeout setting the maximum duration to wait for a pod to be removed after it has been labeled for destruction, and the expected recovery time determining whether a failed pod can recover within the specified timeout or fails the scenario if not recovered within the set time.\n\n\n",
    "retrieved_context": "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
    "time_taken_seconds": 97.16
  },
  {
    "user_input": "If a user wants to disrupt more than one pod in a `pod-scenarios` run, which parameter needs to be adjusted, and what is the default behavior if this parameter is not explicitly set?",
    "generated_answer": " To disrupt more than one pod in a `pod-scenarios` run, you can use the `--disruption-count` parameter and specify the number of pods to disrupt. If this parameter is not explicitly set, the default behavior is to disrupt only one pod.",
    "retrieved_context": "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nWhy  pod  scenarios  are  important:   \n \nUse  Cases  and  Importance  of  Pod-Level  Chaos  Scenarios  \n1.  Single  Pod  Deletion  \u25cf  Use  Case:  Simulates  unplanned  deletion  of  a  single  pod  \u25cf  Why  It's  Important:  Validates  whether  the  ReplicaSet  or  Deployment  automatically  \ncreates\n \na\n \nreplacement.\n \u25cf  Customer  Impact:  Ensures  continuous  service  even  if  a  pod  unexpectedly  crashes.  \u25cf  Recovery  Timing:  Typically  <10  seconds  for  stateless  apps  (seen  in  Krkn  telemetry  \noutput).\n \u25cf  HA  Indicator:  Pod  is  automatically  rescheduled  and  becomes  Ready  without  manual  \nintervention.\n  Kubectl  delete  pod  <pod-name> delete  pod  <pod-name>  Kubectl  get  pods  #  watch  for  new  pods \n2.  Multiple  Pods  Deleted  Simultaneously  \u25cf  Use  Case:  Simulates  a  larger  failure  event,  such  as  a  node  crash  or  AZ  outage.  \u25cf  Why  It's  Important:  Tests  whether  the  system  has  enough  resources  and  policies  to  \nrecover",
    "time_taken_seconds": 71.74
  },
  {
    "user_input": "What is the default scope for targeting pods in a `krknctl run pod-scenarios` execution if no specific namespace, label, or name pattern is provided by the user?",
    "generated_answer": " \nThe default scope for targeting pods in a `krknctl run pod-scenarios` execution without a specific namespace, label, or name pattern is the entire cluster (i.e., `openshift-*` namespace).",
    "retrieved_context": "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario",
    "time_taken_seconds": 79.5
  },
  {
    "user_input": "How can a user obtain a comprehensive list of all configurable options and their descriptions for the `krknctl run pod-scenarios` command?",
    "generated_answer": " To obtain a comprehensive list of all configurable options and their descriptions for the `krknctl run pod-scenarios` command, you can use the `--help` option along with the `--configuration` flag.\nHere's an example of how to do this:\n$ krknctl run pod-scenarios --help --configuration\nThis will display a list of all available scenario options, along with their descriptions and default values.\nNote that some scenario options may have specific requirements or limitations, such as the need for certain environment variables to be set or the use of specific Kubernetes resources. Be sure to consult the relevant documentation or contact the author of the scenario for more information on how to use it correctly.",
    "retrieved_context": "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*",
    "time_taken_seconds": 77.85
  },
  {
    "user_input": "Differentiate between the 'Single Pod Deletion' and 'Multiple Pods Deleted Simultaneously' chaos scenarios regarding their simulated failure types and the primary customer impact each aims to validate or expose.",
    "generated_answer": "  Single Pod Deletion and Multiple Pods Deleted Simultaneously are two different chaos scenarios used to validate or expose different aspects of a system's behavior.\nSingle Pod Deletion scenario validates whether the ReplicaSet or Deployment automatically creates a new replication unit when a pod is deleted unexpectedly, ensuring continuous service even if a pod crashes. This scenario typically has a recovery time of less than 10 seconds for stateless apps (as seen in Krkn telemetry output).\nOn the other hand, Multiple Pods Deleted Simultaneously scenario tests whether the system has enough resources and policies to recover from a larger failure event, such as a node crash or AZ outage. This scenario simulates unplanned deletion of multiple pods simultaneously, exposing the system's ability to handle concurrent failures and ensure resource availability.\nBy running these chaos scenarios, you can identify potential issues in your system's behavior under different failure modes and improve its overall resilience and reliability.",
    "retrieved_context": "Why  pod  scenarios  are  important:   \n \nUse  Cases  and  Importance  of  Pod-Level  Chaos  Scenarios  \n1.  Single  Pod  Deletion  \u25cf  Use  Case:  Simulates  unplanned  deletion  of  a  single  pod  \u25cf  Why  It's  Important:  Validates  whether  the  ReplicaSet  or  Deployment  automatically  \ncreates\n \na\n \nreplacement.\n \u25cf  Customer  Impact:  Ensures  continuous  service  even  if  a  pod  unexpectedly  crashes.  \u25cf  Recovery  Timing:  Typically  <10  seconds  for  stateless  apps  (seen  in  Krkn  telemetry  \noutput).\n \u25cf  HA  Indicator:  Pod  is  automatically  rescheduled  and  becomes  Ready  without  manual  \nintervention.\n  Kubectl  delete  pod  <pod-name> delete  pod  <pod-name>  Kubectl  get  pods  #  watch  for  new  pods \n2.  Multiple  Pods  Deleted  Simultaneously  \u25cf  Use  Case:  Simulates  a  larger  failure  event,  such  as  a  node  crash  or  AZ  outage.  \u25cf  Why  It's  Important:  Tests  whether  the  system  has  enough  resources  and  policies  to  \nrecover\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:\n\nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario \nKill  a  pod.  :heavy_check_mark:  \nEtcd Kills  a  single/multiple  etcd  replicas.  \n:heavy_check_mark:",
    "time_taken_seconds": 81.79
  },
  {
    "user_input": "Explain the significance of 'Pod Eviction' as a chaos scenario, detailing its typical triggers and the specific configurations that are crucial for ensuring zero customer impact during such an event.",
    "generated_answer": "  Pod Eviction is a chaos scenario that simulates soft disruption of a pod, which is triggered by Kubernetes itself during node upgrades or scaling down. The configuration for this scenario typically includes the namespace pattern, label selector, and recovery time. The customer impact for this scenario should be zero if readiness/liveness probes and PDBs are correctly configured. The HA indicator for this scenario is that rolling disruption does not take down the whole application.\nIn order to answer questions about chaos scenarios, it would be helpful to have more information about the specific context and use case. Can you provide more details or clarify which scenario you are asking about?",
    "retrieved_context": "Why  pod  scenarios  are  important:   \n \nUse  Cases  and  Importance  of  Pod-Level  Chaos  Scenarios  \n1.  Single  Pod  Deletion  \u25cf  Use  Case:  Simulates  unplanned  deletion  of  a  single  pod  \u25cf  Why  It's  Important:  Validates  whether  the  ReplicaSet  or  Deployment  automatically  \ncreates\n \na\n \nreplacement.\n \u25cf  Customer  Impact:  Ensures  continuous  service  even  if  a  pod  unexpectedly  crashes.  \u25cf  Recovery  Timing:  Typically  <10  seconds  for  stateless  apps  (seen  in  Krkn  telemetry  \noutput).\n \u25cf  HA  Indicator:  Pod  is  automatically  rescheduled  and  becomes  Ready  without  manual  \nintervention.\n  Kubectl  delete  pod  <pod-name> delete  pod  <pod-name>  Kubectl  get  pods  #  watch  for  new  pods \n2.  Multiple  Pods  Deleted  Simultaneously  \u25cf  Use  Case:  Simulates  a  larger  failure  event,  such  as  a  node  crash  or  AZ  outage.  \u25cf  Why  It's  Important:  Tests  whether  the  system  has  enough  resources  and  policies  to  \nrecover\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nrecover\n \ngracefully.\n \u25cf  Customer  Impact:  If  all  pods  of  a  service  fail,  user  experience  is  directly  impacted.  \u25cf  HA  Indicator:  Application  can  continue  functioning  from  other  replicas  across  \nzones/nodes.\n \n \n3.  Pod  Eviction  (Soft  Disruption)  \u25cf  Use  Case:  Triggered  by  Kubernetes  itself  during  node  upgrades  or  scaling  down.  \u25cf  Why  It's  Important:  Ensures  graceful  termination  and  restart  elsewhere  without  user  \nimpact.\n \u25cf  Customer  Impact:  Should  be  zero  if  readiness/liveness  probes  and  PDBs  are  correctly  \nconfigured.\n \u25cf  HA  Indicator:  Rolling  disruption  does  not  take  down  the  whole  application.  \n \nHow  to  Know  If  It's  Highly  Available\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
    "time_taken_seconds": 78.49
  },
  {
    "user_input": "What specific metrics and observations from Krkn telemetry are crucial for quantitatively assessing the high availability of an application after a chaos engineering run?",
    "generated_answer": "\nKrkn telemetry metrics that are crucial for quantitatively assessing the high availability of an application after a chaos engineering run include:\n1. Recovery time: The time it takes for disrupted pods to recover, which can indicate the effectiveness of the chaos injection and the reliability of the application.\n2. Pod reschedule latency: The time it takes for Kubernetes to reschedule disrupted pods, which can provide insights into the cluster's ability to handle the chaos injection and recover from failures.\n3. Service uptime: The duration that the service remains available during and after the chaos injection, which can help evaluate the application's high availability capabilities.\n4. Downtime: The time period when the service is not available, which can provide information on the impact of the chaos injection on the application's overall performance and uptime.\n5. Service failures: The number of times the service fails during and after the chaos injection, which can help assess the application's reliability and resilience to failures.\n6. Pod termination time: The time it takes for disrupted pods to terminate",
    "retrieved_context": "1.  Multiple  Replicas  Exist:  Confirmed  by  checking  kubectl  get  deploy and  seeing  >1  \nreplicas.\n 2.  Pods  Distributed  Across  Nodes/availability  zones:  Using  topologySpreadConstraints or  observing  pod  distribution  in  kubectl  get  pods  \n-o\n \nwide.  3.  Service  Uptime  Remains  Unaffected:  During  chaos  test,  verify  app  availability  (  \nsynthetic\n \nprobes,\n \nPrometheus\n \nalerts,\n \netc).\n 4.  Recovery  Is  Automatic:  No  manual  intervention  needed  to  restore  service.  5.  Krkn  Telemetry  Indicators:  End  of  run  data  includes  recovery  times,  pod  reschedule  \nlatency,\n \nand\n \nservice\n \ndowntime\n \nwhich\n \nare\n \nvital\n \nmetrics\n \nfor\n \nassessing\n \nHA.\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
    "time_taken_seconds": 97.84
  },
  {
    "user_input": "Beyond automatic recovery, what are the key architectural and operational indicators, as described in the text, that confirm an application is highly available in a Kubernetes environment?",
    "generated_answer": "  Based on the provided context, we can confirm that an application is highly available in a Kubernetes environment by checking for the following indicators:\n\n1. Multiple replicas exist: Checking kubectl get deploy to see >1 replicas.\n2. Pods are distributed across nodes/availability zones: Using topologySpreadConstraints or observing pod distribution in kubectl get pods wide.\n3. Service uptime remains unaffected during chaos tests, as confirmed by synthetic probes, Prometheus alerts, and end-of-run data including recovery times, pod reschedule latency, and service downtime.\n4. Recovery is automatic: No manual intervention is needed to restore service.\n5. KRKN telemetry indicators: End-of-run data includes recovery times, pod rescheduling latency, and service downtime.\n6. Customer impact: If all pods of a service fail, user experience is directly impacted.\n7. HA indicator: Application can continue functioning from other replicas across zones/nodes.\n8. Pod eviction (soft disruption): Triggered",
    "retrieved_context": "1.  Multiple  Replicas  Exist:  Confirmed  by  checking  kubectl  get  deploy and  seeing  >1  \nreplicas.\n 2.  Pods  Distributed  Across  Nodes/availability  zones:  Using  topologySpreadConstraints or  observing  pod  distribution  in  kubectl  get  pods  \n-o\n \nwide.  3.  Service  Uptime  Remains  Unaffected:  During  chaos  test,  verify  app  availability  (  \nsynthetic\n \nprobes,\n \nPrometheus\n \nalerts,\n \netc).\n 4.  Recovery  Is  Automatic:  No  manual  intervention  needed  to  restore  service.  5.  Krkn  Telemetry  Indicators:  End  of  run  data  includes  recovery  times,  pod  reschedule  \nlatency,\n \nand\n \nservice\n \ndowntime\n \nwhich\n \nare\n \nvital\n \nmetrics\n \nfor\n \nassessing\n \nHA.\n\nrecover\n \ngracefully.\n \u25cf  Customer  Impact:  If  all  pods  of  a  service  fail,  user  experience  is  directly  impacted.  \u25cf  HA  Indicator:  Application  can  continue  functioning  from  other  replicas  across  \nzones/nodes.\n \n \n3.  Pod  Eviction  (Soft  Disruption)  \u25cf  Use  Case:  Triggered  by  Kubernetes  itself  during  node  upgrades  or  scaling  down.  \u25cf  Why  It's  Important:  Ensures  graceful  termination  and  restart  elsewhere  without  user  \nimpact.\n \u25cf  Customer  Impact:  Should  be  zero  if  readiness/liveness  probes  and  PDBs  are  correctly  \nconfigured.\n \u25cf  HA  Indicator:  Rolling  disruption  does  not  take  down  the  whole  application.  \n \nHow  to  Know  If  It's  Highly  Available\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:\n\nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario \nKill  a  pod.  :heavy_check_mark:  \nEtcd Kills  a  single/multiple  etcd  replicas.  \n:heavy_check_mark:",
    "time_taken_seconds": 79.67
  },
  {
    "user_input": "How does the 'Single Pod Deletion' scenario specifically validate the resilience mechanisms of Kubernetes, and what is the expected recovery timing for stateless applications in this context?",
    "generated_answer": "  The 'Single Pod Deletion' scenario specifically validates the resilience mechanisms of Kubernetes by simulating an unplanned deletion of a single pod. When this happens, the ReplicaSet or Deployment automatically creates a replacement pod without manual intervention. The expected recovery timing for stateless applications in this context is typically less than 10 seconds, as observed in Krkn telemetry output. This indicates that the system has enough resources and policies to recover gracefully and continue functioning without any user impact.",
    "retrieved_context": "Why  pod  scenarios  are  important:   \n \nUse  Cases  and  Importance  of  Pod-Level  Chaos  Scenarios  \n1.  Single  Pod  Deletion  \u25cf  Use  Case:  Simulates  unplanned  deletion  of  a  single  pod  \u25cf  Why  It's  Important:  Validates  whether  the  ReplicaSet  or  Deployment  automatically  \ncreates\n \na\n \nreplacement.\n \u25cf  Customer  Impact:  Ensures  continuous  service  even  if  a  pod  unexpectedly  crashes.  \u25cf  Recovery  Timing:  Typically  <10  seconds  for  stateless  apps  (seen  in  Krkn  telemetry  \noutput).\n \u25cf  HA  Indicator:  Pod  is  automatically  rescheduled  and  becomes  Ready  without  manual  \nintervention.\n  Kubectl  delete  pod  <pod-name> delete  pod  <pod-name>  Kubectl  get  pods  #  watch  for  new  pods \n2.  Multiple  Pods  Deleted  Simultaneously  \u25cf  Use  Case:  Simulates  a  larger  failure  event,  such  as  a  node  crash  or  AZ  outage.  \u25cf  Why  It's  Important:  Tests  whether  the  system  has  enough  resources  and  policies  to  \nrecover\n\nrecover\n \ngracefully.\n \u25cf  Customer  Impact:  If  all  pods  of  a  service  fail,  user  experience  is  directly  impacted.  \u25cf  HA  Indicator:  Application  can  continue  functioning  from  other  replicas  across  \nzones/nodes.\n \n \n3.  Pod  Eviction  (Soft  Disruption)  \u25cf  Use  Case:  Triggered  by  Kubernetes  itself  during  node  upgrades  or  scaling  down.  \u25cf  Why  It's  Important:  Ensures  graceful  termination  and  restart  elsewhere  without  user  \nimpact.\n \u25cf  Customer  Impact:  Should  be  zero  if  readiness/liveness  probes  and  PDBs  are  correctly  \nconfigured.\n \u25cf  HA  Indicator:  Rolling  disruption  does  not  take  down  the  whole  application.  \n \nHow  to  Know  If  It's  Highly  Available\n\n1.  Multiple  Replicas  Exist:  Confirmed  by  checking  kubectl  get  deploy and  seeing  >1  \nreplicas.\n 2.  Pods  Distributed  Across  Nodes/availability  zones:  Using  topologySpreadConstraints or  observing  pod  distribution  in  kubectl  get  pods  \n-o\n \nwide.  3.  Service  Uptime  Remains  Unaffected:  During  chaos  test,  verify  app  availability  (  \nsynthetic\n \nprobes,\n \nPrometheus\n \nalerts,\n \netc).\n 4.  Recovery  Is  Automatic:  No  manual  intervention  needed  to  restore  service.  5.  Krkn  Telemetry  Indicators:  End  of  run  data  includes  recovery  times,  pod  reschedule  \nlatency,\n \nand\n \nservice\n \ndowntime\n \nwhich\n \nare\n \nvital\n \nmetrics\n \nfor\n \nassessing\n \nHA.\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario",
    "time_taken_seconds": 74.45
  },
  {
    "user_input": "What is the primary concern regarding customer impact when 'Multiple Pods Deleted Simultaneously' occurs, and what architectural characteristic helps mitigate this impact to ensure high availability?",
    "generated_answer": "  When multiple pods are deleted simultaneously, the primary concern is customer impact, as it can result in a prolonged downtime for the application. To mitigate this impact and ensure high availability, Kubernetes provides architectural characteristics such as ReplicaSets or Deployments, which automatically create new replicas of a pod after deletion, ensuring continuous service. Additionally, Kubernetes can distribute the remaining replicas across multiple nodes to maintain service availability even if one or more nodes fail. By monitoring these indicators and assessing the HA configuration, operators can ensure that their application remains highly available in the face of simultaneous pod deletions.",
    "retrieved_context": "Why  pod  scenarios  are  important:   \n \nUse  Cases  and  Importance  of  Pod-Level  Chaos  Scenarios  \n1.  Single  Pod  Deletion  \u25cf  Use  Case:  Simulates  unplanned  deletion  of  a  single  pod  \u25cf  Why  It's  Important:  Validates  whether  the  ReplicaSet  or  Deployment  automatically  \ncreates\n \na\n \nreplacement.\n \u25cf  Customer  Impact:  Ensures  continuous  service  even  if  a  pod  unexpectedly  crashes.  \u25cf  Recovery  Timing:  Typically  <10  seconds  for  stateless  apps  (seen  in  Krkn  telemetry  \noutput).\n \u25cf  HA  Indicator:  Pod  is  automatically  rescheduled  and  becomes  Ready  without  manual  \nintervention.\n  Kubectl  delete  pod  <pod-name> delete  pod  <pod-name>  Kubectl  get  pods  #  watch  for  new  pods \n2.  Multiple  Pods  Deleted  Simultaneously  \u25cf  Use  Case:  Simulates  a  larger  failure  event,  such  as  a  node  crash  or  AZ  outage.  \u25cf  Why  It's  Important:  Tests  whether  the  system  has  enough  resources  and  policies  to  \nrecover\n\nrecover\n \ngracefully.\n \u25cf  Customer  Impact:  If  all  pods  of  a  service  fail,  user  experience  is  directly  impacted.  \u25cf  HA  Indicator:  Application  can  continue  functioning  from  other  replicas  across  \nzones/nodes.\n \n \n3.  Pod  Eviction  (Soft  Disruption)  \u25cf  Use  Case:  Triggered  by  Kubernetes  itself  during  node  upgrades  or  scaling  down.  \u25cf  Why  It's  Important:  Ensures  graceful  termination  and  restart  elsewhere  without  user  \nimpact.\n \u25cf  Customer  Impact:  Should  be  zero  if  readiness/liveness  probes  and  PDBs  are  correctly  \nconfigured.\n \u25cf  HA  Indicator:  Rolling  disruption  does  not  take  down  the  whole  application.  \n \nHow  to  Know  If  It's  Highly  Available\n\n1.  Multiple  Replicas  Exist:  Confirmed  by  checking  kubectl  get  deploy and  seeing  >1  \nreplicas.\n 2.  Pods  Distributed  Across  Nodes/availability  zones:  Using  topologySpreadConstraints or  observing  pod  distribution  in  kubectl  get  pods  \n-o\n \nwide.  3.  Service  Uptime  Remains  Unaffected:  During  chaos  test,  verify  app  availability  (  \nsynthetic\n \nprobes,\n \nPrometheus\n \nalerts,\n \netc).\n 4.  Recovery  Is  Automatic:  No  manual  intervention  needed  to  restore  service.  5.  Krkn  Telemetry  Indicators:  End  of  run  data  includes  recovery  times,  pod  reschedule  \nlatency,\n \nand\n \nservice\n \ndowntime\n \nwhich\n \nare\n \nvital\n \nmetrics\n \nfor\n \nassessing\n \nHA.\n\nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario \nKill  a  pod.  :heavy_check_mark:  \nEtcd Kills  a  single/multiple  etcd  replicas.  \n:heavy_check_mark:",
    "time_taken_seconds": 76.61
  },
  {
    "user_input": "Describe the role of `topologySpreadConstraints` in achieving high availability and how their effective implementation can be verified using standard Kubernetes commands.",
    "generated_answer": " TopologySpreadConstraints is a Kubernetes feature that helps ensure pods are spread across multiple nodes and availability zones to achieve high availability. It can be implemented using the `topology.kubernetes.io/spread` annotation on pods, which specifies the desired topology for the pod (e.g., \"node-level\" or \"zone-level\").\nTo verify the effective implementation of TopologySpreadConstraints using standard Kubernetes commands, you can use `kubectl get pods -o yaml` to retrieve a list of pods and their annotations, including the `topology.kubernetes.io/spread` annotation. You can then check if the desired topology is being enforced for each pod by comparing the actual annotation value with the desired value.\nAlternatively, you can use `kubectl topologyspread` command to check if the spread constraints are being honored for a given set of pods. This command will show you the current state of the pods and whether they are compliant with the desired topology.",
    "retrieved_context": "Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario \nKill  a  pod.  :heavy_check_mark:  \nEtcd Kills  a  single/multiple  etcd  replicas.  \n:heavy_check_mark:\n\n1.  Multiple  Replicas  Exist:  Confirmed  by  checking  kubectl  get  deploy and  seeing  >1  \nreplicas.\n 2.  Pods  Distributed  Across  Nodes/availability  zones:  Using  topologySpreadConstraints or  observing  pod  distribution  in  kubectl  get  pods  \n-o\n \nwide.  3.  Service  Uptime  Remains  Unaffected:  During  chaos  test,  verify  app  availability  (  \nsynthetic\n \nprobes,\n \nPrometheus\n \nalerts,\n \netc).\n 4.  Recovery  Is  Automatic:  No  manual  intervention  needed  to  restore  service.  5.  Krkn  Telemetry  Indicators:  End  of  run  data  includes  recovery  times,  pod  reschedule  \nlatency,\n \nand\n \nservice\n \ndowntime\n \nwhich\n \nare\n \nvital\n \nmetrics\n \nfor\n \nassessing\n \nHA.",
    "time_taken_seconds": 79.81
  },
  {
    "user_input": "In the context of chaos engineering, what does 'Recovery Is Automatic' signify as a high availability indicator, and why is the absence of manual intervention considered critical for true HA?",
    "generated_answer": " Recovery  is  automatic  in  this  context  because  no  manual  intervention  is  needed  to  restore  service  after  a  pod  failure.  The  system  can  automatically  reschedule  the  pod  and  ensure  continuity  of  service.  \n\n\n",
    "retrieved_context": "1.  Multiple  Replicas  Exist:  Confirmed  by  checking  kubectl  get  deploy and  seeing  >1  \nreplicas.\n 2.  Pods  Distributed  Across  Nodes/availability  zones:  Using  topologySpreadConstraints or  observing  pod  distribution  in  kubectl  get  pods  \n-o\n \nwide.  3.  Service  Uptime  Remains  Unaffected:  During  chaos  test,  verify  app  availability  (  \nsynthetic\n \nprobes,\n \nPrometheus\n \nalerts,\n \netc).\n 4.  Recovery  Is  Automatic:  No  manual  intervention  needed  to  restore  service.  5.  Krkn  Telemetry  Indicators:  End  of  run  data  includes  recovery  times,  pod  reschedule  \nlatency,\n \nand\n \nservice\n \ndowntime\n \nwhich\n \nare\n \nvital\n \nmetrics\n \nfor\n \nassessing\n \nHA.\n\nrecover\n \ngracefully.\n \u25cf  Customer  Impact:  If  all  pods  of  a  service  fail,  user  experience  is  directly  impacted.  \u25cf  HA  Indicator:  Application  can  continue  functioning  from  other  replicas  across  \nzones/nodes.\n \n \n3.  Pod  Eviction  (Soft  Disruption)  \u25cf  Use  Case:  Triggered  by  Kubernetes  itself  during  node  upgrades  or  scaling  down.  \u25cf  Why  It's  Important:  Ensures  graceful  termination  and  restart  elsewhere  without  user  \nimpact.\n \u25cf  Customer  Impact:  Should  be  zero  if  readiness/liveness  probes  and  PDBs  are  correctly  \nconfigured.\n \u25cf  HA  Indicator:  Rolling  disruption  does  not  take  down  the  whole  application.  \n \nHow  to  Know  If  It's  Highly  Available\n\nWhy  pod  scenarios  are  important:   \n \nUse  Cases  and  Importance  of  Pod-Level  Chaos  Scenarios  \n1.  Single  Pod  Deletion  \u25cf  Use  Case:  Simulates  unplanned  deletion  of  a  single  pod  \u25cf  Why  It's  Important:  Validates  whether  the  ReplicaSet  or  Deployment  automatically  \ncreates\n \na\n \nreplacement.\n \u25cf  Customer  Impact:  Ensures  continuous  service  even  if  a  pod  unexpectedly  crashes.  \u25cf  Recovery  Timing:  Typically  <10  seconds  for  stateless  apps  (seen  in  Krkn  telemetry  \noutput).\n \u25cf  HA  Indicator:  Pod  is  automatically  rescheduled  and  becomes  Ready  without  manual  \nintervention.\n  Kubectl  delete  pod  <pod-name> delete  pod  <pod-name>  Kubectl  get  pods  #  watch  for  new  pods \n2.  Multiple  Pods  Deleted  Simultaneously  \u25cf  Use  Case:  Simulates  a  larger  failure  event,  such  as  a  node  crash  or  AZ  outage.  \u25cf  Why  It's  Important:  Tests  whether  the  system  has  enough  resources  and  policies  to  \nrecover\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:",
    "time_taken_seconds": 76.06
  },
  {
    "user_input": "What is the primary purpose of the `pod_disruption_scenarios` section within a Krkn configuration, and how is a specific scenario file referenced?",
    "generated_answer": " The primary purpose of the `pod_disruption_scenarios` section within a Krkn configuration is to define scenarios for disrupting pods in a Kubernetes or OpenShift cluster. These scenarios are used by the Krkn tool to simulate chaos in the cluster, allowing developers to test and evaluate the resilience of their applications.\nThe `pod_disruption_scenarios` section specifies the scenario file(s) that should be used for disrupting pods. The scenario file contains YAML code that defines the parameters and actions for each scenario. For example, you can define a scenario to kill all pods in a specific namespace with a certain label, or to disable a service in a specific namespace.\nBy default, Krkn will use the `pod_disruption_scenarios` section in the configuration file to inject chaos into the cluster. However, you can also use the `krknctl` command-line tool to run individual scenarios without using the configuration file.",
    "retrieved_context": "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*",
    "time_taken_seconds": 85.69
  },
  {
    "user_input": "How can a user leverage the provided schema file to enhance their experience when creating a Krkn scenario configuration in an IDE?",
    "generated_answer": " To enhance the experience when creating a Krkn scenario configuration in an IDE, you can leverage the provided schema file to get code completion and documentation for the available options. The schema reference should be adjusted to point to the schema file, which will provide you with code completion and documentation for the available options in your IDE.\nAdditionally, you can set any global variable listed here as scenario specific parameters using the --<parameter>:<value> option. You can also use the --env-host option to enable Cerberus to monitor the cluster and pass/fail the scenario post chaos. It is recommended to start Cerberus before injecting the chaos, and set CERBERUS_ENABLED environment variable for the scenario.\nOverall, using the schema file and setting the appropriate parameters can help you create a more robust and efficient Krkn scenario configuration in your IDE.",
    "retrieved_context": "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*",
    "time_taken_seconds": 83.04
  },
  {
    "user_input": "Based on the example configuration, which specific Kubernetes component is targeted for disruption, and what criteria are used to select its pods?",
    "generated_answer": " The specific Kubernetes component targeted for disruption based on the given configuration is \"etcd\". According to the configuration, the scenario aims to kill a single or multiple etcd replicas.\nThe selection criteria used to choose the pods for disruption are:\n* Label selector: k8s-app=kube-scheduler\n* Namespace pattern: ^kube-system$\nThe expected recovery time is set to 120 seconds.",
    "retrieved_context": "Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:\n\nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario \nKill  a  pod.  :heavy_check_mark:  \nEtcd Kills  a  single/multiple  etcd  replicas.  \n:heavy_check_mark:\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario",
    "time_taken_seconds": 67.38
  },
  {
    "user_input": "What is the function of the `krkn_pod_recovery_time` parameter in a Krkn pod disruption scenario, and what is its value in the provided example?",
    "generated_answer": "\nThe  `krkn_pod_recovery_time` parameter specifies the amount of time (in seconds) to wait for pods to recover after they have been disrupted. In the provided example, the value is set to 120 seconds. If the pods do not recover within this time frame, the scenario will fail.",
    "retrieved_context": "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
    "time_taken_seconds": 84.41
  },
  {
    "user_input": "Beyond a general 'basic pod scenario,' what are some of the critical Kubernetes or OpenShift components for which Krkn offers pre-defined chaos scenarios, and are they currently functional?",
    "generated_answer": " \nThe  following  components  of  Kubernetes/OpenShift  have  pre-defined  chaos  scenarios:  \n1. Pods (kube-system namespace) - Disrupt the specified number of pods in the kube-system namespace with a label matching the target pod(s).\n2. Namespaces (openshift-*) - Target any OpenShift namespace randomly and disrupt the specified number of pods.\n3. Labels (app=test, deployment=my-deployment) - Disrupt the pods matching the specified labels in any namespace.\n4. Pod labels (k8s-app=kube-scheduler) - Disrupt the pods matching the specified label in any namespace.\n\nNote: The scenarios are defined in the krkn/config directory and can be customized to meet your specific needs.",
    "retrieved_context": "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:",
    "time_taken_seconds": 108.59
  },
  {
    "user_input": "If a user wanted to specifically target the Kubernetes API server for a chaos experiment, which Krkn scenario would be appropriate, and what action would it perform?",
    "generated_answer": " \nThe  scenario  you  are  looking  for  is  \"kube-apiserver\"  because  it  targets  the  Kubernetes API server.  The  action  performs  a  kill  of  a  single  apiserver  replica,  and  the  recovery  time  is  120  seconds.  \nPlease note that this scenario is not recommended as it can cause significant harm to your cluster. It is important to use chaos engineering scenarios responsibly and only for testing purposes.",
    "retrieved_context": "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nKube  ApiServer Kills  a  single/multiple  kube-apiserver  replicas.  \n:heavy_check_mark:  \nApiServer Kills  a  single/multiple  apiserver  replicas.  \n:heavy_check_mark:  \nPrometheus Kills  a  single/multiple  prometheus  replicas.  \n:heavy_check_mark:  \nOpenShift  System  Pods \nKills  random  pods  running  in  the  OpenShift  system  namespaces.  \n:heavy_check_mark:",
    "time_taken_seconds": 112.31
  },
  {
    "user_input": "How does the 'OpenShift System Pods' chaos scenario differ in its targeting approach compared to component-specific scenarios like 'Etcd' or 'Prometheus'?",
    "generated_answer": " The \"OpenShift System Pods\" chaos scenario differs from component-specific scenarios like \"Etcd\" or \"Prometheus\" in its targeting approach. While component-specific scenarios target specific Kubernetes components, the \"OpenShift System Pods\" scenario targets all pods in the OpenShift system namespace. This means that it can disrupt any pod in the OpenShift system, including those belonging to applications and services.\nIn contrast, component-specific scenarios typically target a single Kubernetes component or group of components, such as etcd or Prometheus. These scenarios are designed to test the resilience and behavior of a specific component or set of components under chaos conditions, rather than disrupting all pods in the OpenShift system.\nOverall, the \"OpenShift System Pods\" scenario is more comprehensive and flexible than component-specific scenarios, as it can be used to test the overall resilience and behavior of the OpenShift system under a wide range of chaos conditions. However, it also requires more careful configuration and tuning to ensure that the desired pods are targeted and disrupted in a controlled manner.",
    "retrieved_context": "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*",
    "time_taken_seconds": 109.89
  },
  {
    "user_input": "What is the purpose of the `id` field within a Krkn scenario configuration, as demonstrated by the `kill-pods` example?",
    "generated_answer": " The `id` field within a Krkn scenario configuration is used to specify the unique identifier for the scenario. In the provided example, the `id` field is set to \"kill-pods\". This identifier is used to refer to the scenario in subsequent commands and can be used to run the scenario using the `krknctl run` command.\nIf you don't know the answer to a question, it's important to say so rather than providing an incorrect or incomplete response.",
    "retrieved_context": "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nNone \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*",
    "time_taken_seconds": 83.45
  },
  {
    "user_input": "Can the `kill-pods` scenario, as configured in the example, disrupt pods located in namespaces other than `kube-system`?",
    "generated_answer": "\nKrkn-hub  disrupts  pods  in  the  specified  namespace.  \nIf  you  want  to  disrupt  pods  in  other  namespaces,  you  will  need  to  set  the  `NAMESPACE`  environment  variable  to  the  desired  namespace  before  running  the  scenario.",
    "retrieved_context": "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nKube  ApiServer Kills  a  single/multiple  kube-apiserver  replicas.  \n:heavy_check_mark:  \nApiServer Kills  a  single/multiple  apiserver  replicas.  \n:heavy_check_mark:  \nPrometheus Kills  a  single/multiple  prometheus  replicas.  \n:heavy_check_mark:  \nOpenShift  System  Pods \nKills  random  pods  running  in  the  OpenShift  system  namespaces.  \n:heavy_check_mark:\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\nShell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:",
    "time_taken_seconds": 91.38
  },
  {
    "user_input": "Describe the hierarchical structure for defining chaos scenarios within the top-level `kraken` configuration block.",
    "generated_answer": "  I  don't  know  the  answer  to  your  question.  \n\nPlease  provide  more  context or clarify  the  question  so  that  I  can  assist  further.",
    "retrieved_context": "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario\n\nShell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help\n\nShell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy\n\n1.  Multiple  Replicas  Exist:  Confirmed  by  checking  kubectl  get  deploy and  seeing  >1  \nreplicas.\n 2.  Pods  Distributed  Across  Nodes/availability  zones:  Using  topologySpreadConstraints or  observing  pod  distribution  in  kubectl  get  pods  \n-o\n \nwide.  3.  Service  Uptime  Remains  Unaffected:  During  chaos  test,  verify  app  availability  (  \nsynthetic\n \nprobes,\n \nPrometheus\n \nalerts,\n \netc).\n 4.  Recovery  Is  Automatic:  No  manual  intervention  needed  to  restore  service.  5.  Krkn  Telemetry  Indicators:  End  of  run  data  includes  recovery  times,  pod  reschedule  \nlatency,\n \nand\n \nservice\n \ndowntime\n \nwhich\n \nare\n \nvital\n \nmetrics\n \nfor\n \nassessing\n \nHA.",
    "time_taken_seconds": 78.67
  }
]}